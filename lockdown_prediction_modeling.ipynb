{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import ast\n",
    "from collections import Counter\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from scipy.stats import randint as sp_randint, uniform\n",
    "import spacy\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import Lasso, LassoCV, LinearRegression, LogisticRegression, Ridge\n",
    "from sklearn.metrics import accuracy_score, auc, log_loss, make_scorer, mean_squared_error, pairwise_distances_argmin_min, precision_recall_curve, precision_score, r2_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import KFold, LeaveOneOut, RandomizedSearchCV, StratifiedKFold, cross_val_predict, cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import torch\n",
    "from torch import nn, optim, tensor\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.forecasting.theta import ThetaModel\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "\n",
    "import warnings                               \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from tqdm import tqdm #A tqdm progress bar shows you how much time has elapsed and the estimated time remaining for the iterable\n",
    "import sklearn.metrics as skmetrics #For evaluation metrics\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "import warnings                               \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "\n",
    "from prophet.diagnostics import cross_validation\n",
    "\n",
    "import pickle\n",
    "\n",
    "from scipy.special import expit  # Sigmoid function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/ianduke/Desktop/Defense_Data_Center/BOP_Closure_Tracking'\n",
    "# reference_attributes = ['full_address', 'bop_region', 'county', 'judicial_district', 'gender']\n",
    "\n",
    "# # Function to load CSVs and find the one with all needed columns\n",
    "# def load_csvs(directory, reference_attributes):\n",
    "#     all_data = {}\n",
    "#     complete_data_file = None\n",
    "    \n",
    "#     for filename in os.listdir(directory):\n",
    "#         if filename.startswith('facilities_') and filename.endswith('.csv'):\n",
    "#             path = os.path.join(directory, filename)\n",
    "#             df = pd.read_csv(path)\n",
    "            \n",
    "#             # Check if this file has all reference attributes\n",
    "#             if all(attr in df.columns for attr in reference_attributes):\n",
    "#                 complete_data_file = df\n",
    "            \n",
    "#             all_data[path] = df\n",
    "    \n",
    "#     return all_data, complete_data_file\n",
    "\n",
    "# # Function to create a reference dictionary from the complete data file\n",
    "# def create_reference_dict(df, reference_attributes):\n",
    "#     ref_dict = {}\n",
    "#     for index, row in df.iterrows():\n",
    "#         ref_dict[row['title']] = {attr: row[attr] for attr in reference_attributes}\n",
    "#     return ref_dict\n",
    "\n",
    "# # Function to fill missing data based on the reference dictionary\n",
    "# def impute_missing_data(all_data, ref_dict, reference_attributes):\n",
    "#     for path, df in all_data.items():\n",
    "#         for attr in reference_attributes:\n",
    "#             if attr not in df.columns:\n",
    "#                 df[attr] = df['title'].map(lambda x: ref_dict[x][attr] if x in ref_dict else None)\n",
    "#         df.to_csv(path, index=False)\n",
    "\n",
    "# # Main script execution\n",
    "# all_data, complete_data_file = load_csvs(directory, reference_attributes)\n",
    "\n",
    "# if complete_data_file is not None:\n",
    "#     ref_dict = create_reference_dict(complete_data_file, reference_attributes)\n",
    "#     impute_missing_data(all_data, ref_dict, reference_attributes)\n",
    "# else:\n",
    "#     print(\"No complete data file found. Please check the dataset or provide a reference.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master DataFrame created and saved to /Users/ianduke/Desktop/Defense_Data_Center/BOP_Closure_Tracking/master_dataframe.csv.\n"
     ]
    }
   ],
   "source": [
    "# Function to concatenate all CSV files into one DataFrame\n",
    "def concatenate_csvs(directory):\n",
    "    dfs = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith('facilities_') and filename.endswith('.csv'):\n",
    "            path = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(path)\n",
    "            dfs.append(df)\n",
    "    \n",
    "    master_df = pd.concat(dfs, ignore_index=True)\n",
    "    return master_df\n",
    "\n",
    "# Main script execution\n",
    "master_df = concatenate_csvs(directory)\n",
    "\n",
    "# Save the concatenated DataFrame to a new CSV file\n",
    "output_path = os.path.join(directory, 'master_dataframe.csv')\n",
    "master_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Master DataFrame created and saved to {output_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/ianduke/Desktop/Defense_Data_Center/BOP_Closure_Tracking/master_dataframe.csv')\n",
    "data = data.drop(columns = ['zip_code'])\n",
    "data = data.drop(columns = ['operation_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "data['population'] = data['population'].astype(str).str.replace(',', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>population</th>\n",
       "      <th>visiting_status</th>\n",
       "      <th>datetime_of_data</th>\n",
       "      <th>full_address</th>\n",
       "      <th>bop_region</th>\n",
       "      <th>county</th>\n",
       "      <th>judicial_district</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>FCI YAZOO CITY MEDIUM</td>\n",
       "      <td>1511</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-04-23 11:43:57 PDT</td>\n",
       "      <td>2225 HALEY BARBOUR PKWY, YAZOO CITY, MS 39194</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>YAZOO</td>\n",
       "      <td>Southern Mississippi</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>FCI YAZOO CITY LOW</td>\n",
       "      <td>1362</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-04-23 11:43:41 PDT</td>\n",
       "      <td>2225 HALEY BARBOUR PARKWAY, YAZOO CITY, MS 39194</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>YAZOO</td>\n",
       "      <td>Southern Mississippi</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>FCI YAZOO CITY LOW II</td>\n",
       "      <td>1302</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-04-23 11:43:26 PDT</td>\n",
       "      <td>2225 HALEY BARBOUR PARKWAY, YAZOO CITY, MS 39194</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>YAZOO</td>\n",
       "      <td>Southern Mississippi</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>FPC YANKTON</td>\n",
       "      <td>467</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-04-23 11:43:10 PDT</td>\n",
       "      <td>1016 DOUGLAS AVENUE, YANKTON, SD 57078</td>\n",
       "      <td>North Central Region</td>\n",
       "      <td>Yankton</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>FCI WILLIAMSBURG</td>\n",
       "      <td>1267</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-04-23 11:42:54 PDT</td>\n",
       "      <td>8301 HIGHWAY 521, SALTERS, SC 29590</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7080</th>\n",
       "      <td>USP ALLENWOOD</td>\n",
       "      <td>324</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2023-09-27 10:22:14 PDT</td>\n",
       "      <td>RT 15,2 MILES N OF ALLENWOOD, ALLENWOOD, PA 17810</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>Union</td>\n",
       "      <td>Middle Pennsylvania</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7079</th>\n",
       "      <td>FCI ALLENWOOD MEDIUM</td>\n",
       "      <td>1273</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2023-09-27 10:22:06 PDT</td>\n",
       "      <td>RT 15, 2 MI N OF ALLENWOOD, WHITE DEER, PA 17810</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>Union</td>\n",
       "      <td>Middle Pennsylvania</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7078</th>\n",
       "      <td>FCI ALLENWOOD LOW</td>\n",
       "      <td>1049</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2023-09-27 10:21:58 PDT</td>\n",
       "      <td>RT 15,2 MILES N OF ALLENWOOD, ALLENWOOD, PA 17810</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>UNION</td>\n",
       "      <td>Middle Pennsylvania</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7077</th>\n",
       "      <td>FCI ALICEVILLE</td>\n",
       "      <td>1656</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2023-09-27 10:21:49 PDT</td>\n",
       "      <td>11070 HIGHWAY 14, ALICEVILLE, AL 35442</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>PICKENS</td>\n",
       "      <td>Northern District of Alabama</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7076</th>\n",
       "      <td>FPC ALDERSON</td>\n",
       "      <td>697</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2023-09-27 10:21:40 PDT</td>\n",
       "      <td>GLEN RAY RD. BOX A, ALDERSON, WV 24910</td>\n",
       "      <td>Mid-Atlantic Region</td>\n",
       "      <td>GREENBRIER</td>\n",
       "      <td>Southern West Virginia</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13054 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title population visiting_status  \\\n",
       "243   FCI YAZOO CITY MEDIUM       1511   Not Suspended   \n",
       "242      FCI YAZOO CITY LOW       1362   Not Suspended   \n",
       "241   FCI YAZOO CITY LOW II       1302   Not Suspended   \n",
       "240             FPC YANKTON        467   Not Suspended   \n",
       "239        FCI WILLIAMSBURG       1267   Not Suspended   \n",
       "...                     ...        ...             ...   \n",
       "7080          USP ALLENWOOD        324   Not Suspended   \n",
       "7079   FCI ALLENWOOD MEDIUM       1273   Not Suspended   \n",
       "7078      FCI ALLENWOOD LOW       1049   Not Suspended   \n",
       "7077         FCI ALICEVILLE       1656   Not Suspended   \n",
       "7076           FPC ALDERSON        697   Not Suspended   \n",
       "\n",
       "             datetime_of_data  \\\n",
       "243   2024-04-23 11:43:57 PDT   \n",
       "242   2024-04-23 11:43:41 PDT   \n",
       "241   2024-04-23 11:43:26 PDT   \n",
       "240   2024-04-23 11:43:10 PDT   \n",
       "239   2024-04-23 11:42:54 PDT   \n",
       "...                       ...   \n",
       "7080  2023-09-27 10:22:14 PDT   \n",
       "7079  2023-09-27 10:22:06 PDT   \n",
       "7078  2023-09-27 10:21:58 PDT   \n",
       "7077  2023-09-27 10:21:49 PDT   \n",
       "7076  2023-09-27 10:21:40 PDT   \n",
       "\n",
       "                                           full_address            bop_region  \\\n",
       "243       2225 HALEY BARBOUR PKWY, YAZOO CITY, MS 39194      Southeast Region   \n",
       "242    2225 HALEY BARBOUR PARKWAY, YAZOO CITY, MS 39194      Southeast Region   \n",
       "241    2225 HALEY BARBOUR PARKWAY, YAZOO CITY, MS 39194      Southeast Region   \n",
       "240              1016 DOUGLAS AVENUE, YANKTON, SD 57078  North Central Region   \n",
       "239                 8301 HIGHWAY 521, SALTERS, SC 29590      Southeast Region   \n",
       "...                                                 ...                   ...   \n",
       "7080  RT 15,2 MILES N OF ALLENWOOD, ALLENWOOD, PA 17810      Northeast Region   \n",
       "7079   RT 15, 2 MI N OF ALLENWOOD, WHITE DEER, PA 17810      Northeast Region   \n",
       "7078  RT 15,2 MILES N OF ALLENWOOD, ALLENWOOD, PA 17810      Northeast Region   \n",
       "7077             11070 HIGHWAY 14, ALICEVILLE, AL 35442      Southeast Region   \n",
       "7076             GLEN RAY RD. BOX A, ALDERSON, WV 24910   Mid-Atlantic Region   \n",
       "\n",
       "            county             judicial_district  gender  \n",
       "243          YAZOO          Southern Mississippi    Male  \n",
       "242          YAZOO          Southern Mississippi    Male  \n",
       "241          YAZOO          Southern Mississippi    Male  \n",
       "240        Yankton                  South Dakota    Male  \n",
       "239   Williamsburg                South Carolina    Male  \n",
       "...            ...                           ...     ...  \n",
       "7080         Union           Middle Pennsylvania    Male  \n",
       "7079         Union           Middle Pennsylvania    Male  \n",
       "7078         UNION           Middle Pennsylvania    Male  \n",
       "7077       PICKENS  Northern District of Alabama  Female  \n",
       "7076    GREENBRIER        Southern West Virginia  Female  \n",
       "\n",
       "[13054 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values(by='datetime_of_data', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    if data.iloc[i]['title'] == 'USP THOMSON':\n",
    "        data.at[i, 'full_address'] = '1100 ONE MILE ROAD, THOMSON, IL 61285'\n",
    "        data.at[i, 'bop_region'] = 'North Central Region'\n",
    "        data.at[i, 'county'] = 'CARROLL'\n",
    "        data.at[i, 'judicial_district'] = 'Northern District of Illinois'\n",
    "        data.at[i, 'gender'] = 'Male'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    if data.iloc[i]['title'] == 'MCC New York':\n",
    "        data.at[i, 'full_address'] = '150 PARK ROW, NEW YORK, NY 10007'\n",
    "        data.at[i, 'bop_region'] = 'Northeast Region'\n",
    "        data.at[i, 'county'] = 'New York'\n",
    "        data.at[i, 'judicial_district'] = 'Southern New York'\n",
    "        data.at[i, 'gender'] = 'Male'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['population'], inplace=True)\n",
    "data = data[data['population'].astype(str).str.lower() != 'nan']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "FCI JESUP    107\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_rows = data[data.isna().any(axis=1)]\n",
    "na_rows['title'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>population</th>\n",
       "      <th>visiting_status</th>\n",
       "      <th>datetime_of_data</th>\n",
       "      <th>full_address</th>\n",
       "      <th>bop_region</th>\n",
       "      <th>county</th>\n",
       "      <th>judicial_district</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>FCI JESUP</td>\n",
       "      <td>1672</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-03-25 19:48:38 PDT</td>\n",
       "      <td>2600 HIGHWAY 301 SOUTH, JESUP, GA 31599</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southern Georgia</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>FCI JESUP</td>\n",
       "      <td>1684</td>\n",
       "      <td>Suspended</td>\n",
       "      <td>2024-04-23 11:26:28 PDT</td>\n",
       "      <td>2600 HIGHWAY 301 SOUTH, JESUP, GA 31599</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southern Georgia</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>FCI JESUP</td>\n",
       "      <td>1655</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-02-03 19:37:24 PST</td>\n",
       "      <td>2600 HIGHWAY 301 SOUTH, JESUP, GA 31599</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southern Georgia</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>FCI JESUP</td>\n",
       "      <td>1654</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-02-20 10:27:26 PST</td>\n",
       "      <td>2600 HIGHWAY 301 SOUTH, JESUP, GA 31599</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southern Georgia</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>FCI JESUP</td>\n",
       "      <td>1655</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-02-06 14:28:42 PST</td>\n",
       "      <td>2600 HIGHWAY 301 SOUTH, JESUP, GA 31599</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southern Georgia</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12500</th>\n",
       "      <td>FCI JESUP</td>\n",
       "      <td>1666</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-01-26 10:24:50 PST</td>\n",
       "      <td>2600 HIGHWAY 301 SOUTH, JESUP, GA 31599</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southern Georgia</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12622</th>\n",
       "      <td>FCI JESUP</td>\n",
       "      <td>1628</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2023-12-03 10:57:09 PST</td>\n",
       "      <td>2600 HIGHWAY 301 SOUTH, JESUP, GA 31599</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southern Georgia</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12744</th>\n",
       "      <td>FCI JESUP</td>\n",
       "      <td>1669</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-04-07 15:15:58 PDT</td>\n",
       "      <td>2600 HIGHWAY 301 SOUTH, JESUP, GA 31599</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southern Georgia</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12866</th>\n",
       "      <td>FCI JESUP</td>\n",
       "      <td>1663</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-02-26 18:29:56 PST</td>\n",
       "      <td>2600 HIGHWAY 301 SOUTH, JESUP, GA 31599</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southern Georgia</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12988</th>\n",
       "      <td>FCI JESUP</td>\n",
       "      <td>1642</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2023-11-13 09:36:02 PST</td>\n",
       "      <td>2600 HIGHWAY 301 SOUTH, JESUP, GA 31599</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southern Georgia</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           title population visiting_status         datetime_of_data  \\\n",
       "56     FCI JESUP       1672   Not Suspended  2024-03-25 19:48:38 PDT   \n",
       "178    FCI JESUP       1684       Suspended  2024-04-23 11:26:28 PDT   \n",
       "300    FCI JESUP       1655   Not Suspended  2024-02-03 19:37:24 PST   \n",
       "422    FCI JESUP       1654   Not Suspended  2024-02-20 10:27:26 PST   \n",
       "544    FCI JESUP       1655   Not Suspended  2024-02-06 14:28:42 PST   \n",
       "...          ...        ...             ...                      ...   \n",
       "12500  FCI JESUP       1666   Not Suspended  2024-01-26 10:24:50 PST   \n",
       "12622  FCI JESUP       1628   Not Suspended  2023-12-03 10:57:09 PST   \n",
       "12744  FCI JESUP       1669   Not Suspended  2024-04-07 15:15:58 PDT   \n",
       "12866  FCI JESUP       1663   Not Suspended  2024-02-26 18:29:56 PST   \n",
       "12988  FCI JESUP       1642   Not Suspended  2023-11-13 09:36:02 PST   \n",
       "\n",
       "                                  full_address        bop_region county  \\\n",
       "56     2600 HIGHWAY 301 SOUTH, JESUP, GA 31599  Southeast Region    NaN   \n",
       "178    2600 HIGHWAY 301 SOUTH, JESUP, GA 31599  Southeast Region    NaN   \n",
       "300    2600 HIGHWAY 301 SOUTH, JESUP, GA 31599  Southeast Region    NaN   \n",
       "422    2600 HIGHWAY 301 SOUTH, JESUP, GA 31599  Southeast Region    NaN   \n",
       "544    2600 HIGHWAY 301 SOUTH, JESUP, GA 31599  Southeast Region    NaN   \n",
       "...                                        ...               ...    ...   \n",
       "12500  2600 HIGHWAY 301 SOUTH, JESUP, GA 31599  Southeast Region    NaN   \n",
       "12622  2600 HIGHWAY 301 SOUTH, JESUP, GA 31599  Southeast Region    NaN   \n",
       "12744  2600 HIGHWAY 301 SOUTH, JESUP, GA 31599  Southeast Region    NaN   \n",
       "12866  2600 HIGHWAY 301 SOUTH, JESUP, GA 31599  Southeast Region    NaN   \n",
       "12988  2600 HIGHWAY 301 SOUTH, JESUP, GA 31599  Southeast Region    NaN   \n",
       "\n",
       "      judicial_district gender  \n",
       "56     Southern Georgia   Male  \n",
       "178    Southern Georgia   Male  \n",
       "300    Southern Georgia   Male  \n",
       "422    Southern Georgia   Male  \n",
       "544    Southern Georgia   Male  \n",
       "...                 ...    ...  \n",
       "12500  Southern Georgia   Male  \n",
       "12622  Southern Georgia   Male  \n",
       "12744  Southern Georgia   Male  \n",
       "12866  Southern Georgia   Male  \n",
       "12988  Southern Georgia   Male  \n",
       "\n",
       "[107 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_rows[na_rows['title'] == 'FCI JESUP']\n",
    "# county info not available on FCI JESUP website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop = True)\n",
    "\n",
    "data['zip_code'] = ''\n",
    "for i in range(len(data)):\n",
    "    data['zip_code'][i] = data['full_address'][i][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['title'] != 'MCC New York']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('/Users/ianduke/Desktop/Defense_Data_Center/BOP_Closure_Tracking/master_dataframe_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Political Affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_political_affiliation(zip_code, api_key):\n",
    "#     url = f\"https://www.googleapis.com/civicinfo/v2/representatives\"\n",
    "#     params = {\n",
    "#         \"address\": zip_code,\n",
    "#         \"key\": api_key,\n",
    "#         \"levels\": \"country\"\n",
    "#     }\n",
    "\n",
    "#     response = requests.get(url, params=params)\n",
    "#     data = response.json()\n",
    "\n",
    "#     if 'officials' not in data:\n",
    "#         return \"No data available for this zip code\"\n",
    "\n",
    "#     party_counts = {}\n",
    "#     for official in data['officials']:\n",
    "#         if 'party' in official:\n",
    "#             party = official['party']\n",
    "#             if party in party_counts:\n",
    "#                 party_counts[party] += 1\n",
    "#             else:\n",
    "#                 party_counts[party] = 1\n",
    "\n",
    "#     # Determine the predominant party\n",
    "#     predominant_party = max(party_counts, key=party_counts.get)\n",
    "#     return predominant_party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_key = 'AIzaSyDn1wgm_mO99zEsn9HLwBvkz3tVWvtVo_A'\n",
    "# # Create dictionary of all zip codes with their affiliation\n",
    "# political_affiliation_dictionary = {}\n",
    "# unique_addresses = data['full_address'].dropna().unique()\n",
    "\n",
    "# for addy in unique_addresses:\n",
    "#     affiliation = get_political_affiliation(addy, api_key)\n",
    "#     political_affiliation_dictionary[addy] = affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_address_components(df, address_column):\n",
    "    # Create new columns with empty strings\n",
    "    df['city'] = ''\n",
    "    df['state'] = ''\n",
    "    df['zip_code'] = ''\n",
    "    \n",
    "    # Iterate over the rows of the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            # Assume the address format is \"STREET, CITY, STATE ZIP\"\n",
    "            parts = row[address_column].split(',')\n",
    "            # If there are at least 2 parts, the second to last is the city\n",
    "            city_state_zip = parts[-1].strip().split(' ')\n",
    "            df.at[index, 'city'] = parts[-2].strip() if len(parts) > 1 else ''\n",
    "            \n",
    "            # Check if there's a space in the last part to separate state and zip\n",
    "            if len(city_state_zip) >= 2:\n",
    "                df.at[index, 'state'] = city_state_zip[0].strip()\n",
    "                df.at[index, 'zip_code'] = city_state_zip[1].strip()\n",
    "            else:  # If there's no space, assume the last part is the state\n",
    "                df.at[index, 'state'] = city_state_zip[0].strip()\n",
    "        except Exception as e:\n",
    "            # Handle any unexpected errors\n",
    "            print(f\"Error processing row {index}: {e}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>population</th>\n",
       "      <th>visiting_status</th>\n",
       "      <th>datetime_of_data</th>\n",
       "      <th>full_address</th>\n",
       "      <th>bop_region</th>\n",
       "      <th>county</th>\n",
       "      <th>judicial_district</th>\n",
       "      <th>gender</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FPC ALDERSON</td>\n",
       "      <td>695</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-03-25 19:34:07 PDT</td>\n",
       "      <td>GLEN RAY RD. BOX A, ALDERSON, WV 24910</td>\n",
       "      <td>Mid-Atlantic Region</td>\n",
       "      <td>GREENBRIER</td>\n",
       "      <td>Southern West Virginia</td>\n",
       "      <td>Female</td>\n",
       "      <td>24910</td>\n",
       "      <td>ALDERSON</td>\n",
       "      <td>WV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FCI ALICEVILLE</td>\n",
       "      <td>1569</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-03-25 19:34:23 PDT</td>\n",
       "      <td>11070 HIGHWAY 14, ALICEVILLE, AL 35442</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>PICKENS</td>\n",
       "      <td>Northern District of Alabama</td>\n",
       "      <td>Female</td>\n",
       "      <td>35442</td>\n",
       "      <td>ALICEVILLE</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FCI ALLENWOOD LOW</td>\n",
       "      <td>976</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-03-25 19:34:38 PDT</td>\n",
       "      <td>RT 15,2 MILES N OF ALLENWOOD, ALLENWOOD, PA 17810</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>UNION</td>\n",
       "      <td>Middle Pennsylvania</td>\n",
       "      <td>Male</td>\n",
       "      <td>17810</td>\n",
       "      <td>ALLENWOOD</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FCI ALLENWOOD MEDIUM</td>\n",
       "      <td>1272</td>\n",
       "      <td>Suspended</td>\n",
       "      <td>2024-03-25 19:34:54 PDT</td>\n",
       "      <td>RT 15, 2 MI N OF ALLENWOOD, WHITE DEER, PA 17810</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>Union</td>\n",
       "      <td>Middle Pennsylvania</td>\n",
       "      <td>Male</td>\n",
       "      <td>17810</td>\n",
       "      <td>WHITE DEER</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USP ALLENWOOD</td>\n",
       "      <td>282</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-03-25 19:35:09 PDT</td>\n",
       "      <td>RT 15,2 MILES N OF ALLENWOOD, ALLENWOOD, PA 17810</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>Union</td>\n",
       "      <td>Middle Pennsylvania</td>\n",
       "      <td>Male</td>\n",
       "      <td>17810</td>\n",
       "      <td>ALLENWOOD</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12999</th>\n",
       "      <td>FCI WILLIAMSBURG</td>\n",
       "      <td>1409</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2023-11-13 09:52:01 PST</td>\n",
       "      <td>8301 HIGHWAY 521, SALTERS, SC 29590</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Male</td>\n",
       "      <td>29590</td>\n",
       "      <td>SALTERS</td>\n",
       "      <td>SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13000</th>\n",
       "      <td>FPC YANKTON</td>\n",
       "      <td>410</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2023-11-13 09:52:17 PST</td>\n",
       "      <td>1016 DOUGLAS AVENUE, YANKTON, SD 57078</td>\n",
       "      <td>North Central Region</td>\n",
       "      <td>Yankton</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>Male</td>\n",
       "      <td>57078</td>\n",
       "      <td>YANKTON</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13001</th>\n",
       "      <td>FCI YAZOO CITY MEDIUM</td>\n",
       "      <td>1439</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2023-11-13 09:52:33 PST</td>\n",
       "      <td>2225 HALEY BARBOUR PARKWAY, YAZOO CITY, MS 39194</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>YAZOO</td>\n",
       "      <td>Southern Mississippi</td>\n",
       "      <td>Male</td>\n",
       "      <td>39194</td>\n",
       "      <td>YAZOO CITY</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13002</th>\n",
       "      <td>FCI YAZOO CITY LOW</td>\n",
       "      <td>1487</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2023-11-13 09:52:49 PST</td>\n",
       "      <td>2225 HALEY BARBOUR PARKWAY, YAZOO CITY, MS 39194</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>YAZOO</td>\n",
       "      <td>Southern Mississippi</td>\n",
       "      <td>Male</td>\n",
       "      <td>39194</td>\n",
       "      <td>YAZOO CITY</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13003</th>\n",
       "      <td>USP YAZOO CITY</td>\n",
       "      <td>1502</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2023-11-13 09:53:05 PST</td>\n",
       "      <td>2225 HALEY BARBOUR PKWY, YAZOO CITY, MS 39194</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>YAZOO</td>\n",
       "      <td>Southern Mississippi</td>\n",
       "      <td>Male</td>\n",
       "      <td>39194</td>\n",
       "      <td>YAZOO CITY</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13003 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title population visiting_status  \\\n",
       "0               FPC ALDERSON        695   Not Suspended   \n",
       "1             FCI ALICEVILLE       1569   Not Suspended   \n",
       "2          FCI ALLENWOOD LOW        976   Not Suspended   \n",
       "3       FCI ALLENWOOD MEDIUM       1272       Suspended   \n",
       "4              USP ALLENWOOD        282   Not Suspended   \n",
       "...                      ...        ...             ...   \n",
       "12999       FCI WILLIAMSBURG       1409   Not Suspended   \n",
       "13000            FPC YANKTON        410   Not Suspended   \n",
       "13001  FCI YAZOO CITY MEDIUM       1439   Not Suspended   \n",
       "13002     FCI YAZOO CITY LOW       1487   Not Suspended   \n",
       "13003         USP YAZOO CITY       1502   Not Suspended   \n",
       "\n",
       "              datetime_of_data  \\\n",
       "0      2024-03-25 19:34:07 PDT   \n",
       "1      2024-03-25 19:34:23 PDT   \n",
       "2      2024-03-25 19:34:38 PDT   \n",
       "3      2024-03-25 19:34:54 PDT   \n",
       "4      2024-03-25 19:35:09 PDT   \n",
       "...                        ...   \n",
       "12999  2023-11-13 09:52:01 PST   \n",
       "13000  2023-11-13 09:52:17 PST   \n",
       "13001  2023-11-13 09:52:33 PST   \n",
       "13002  2023-11-13 09:52:49 PST   \n",
       "13003  2023-11-13 09:53:05 PST   \n",
       "\n",
       "                                            full_address  \\\n",
       "0                 GLEN RAY RD. BOX A, ALDERSON, WV 24910   \n",
       "1                 11070 HIGHWAY 14, ALICEVILLE, AL 35442   \n",
       "2      RT 15,2 MILES N OF ALLENWOOD, ALLENWOOD, PA 17810   \n",
       "3       RT 15, 2 MI N OF ALLENWOOD, WHITE DEER, PA 17810   \n",
       "4      RT 15,2 MILES N OF ALLENWOOD, ALLENWOOD, PA 17810   \n",
       "...                                                  ...   \n",
       "12999                8301 HIGHWAY 521, SALTERS, SC 29590   \n",
       "13000             1016 DOUGLAS AVENUE, YANKTON, SD 57078   \n",
       "13001   2225 HALEY BARBOUR PARKWAY, YAZOO CITY, MS 39194   \n",
       "13002   2225 HALEY BARBOUR PARKWAY, YAZOO CITY, MS 39194   \n",
       "13003      2225 HALEY BARBOUR PKWY, YAZOO CITY, MS 39194   \n",
       "\n",
       "                 bop_region        county             judicial_district  \\\n",
       "0       Mid-Atlantic Region    GREENBRIER        Southern West Virginia   \n",
       "1          Southeast Region       PICKENS  Northern District of Alabama   \n",
       "2          Northeast Region         UNION           Middle Pennsylvania   \n",
       "3          Northeast Region         Union           Middle Pennsylvania   \n",
       "4          Northeast Region         Union           Middle Pennsylvania   \n",
       "...                     ...           ...                           ...   \n",
       "12999      Southeast Region  Williamsburg                South Carolina   \n",
       "13000  North Central Region       Yankton                  South Dakota   \n",
       "13001      Southeast Region         YAZOO          Southern Mississippi   \n",
       "13002      Southeast Region         YAZOO          Southern Mississippi   \n",
       "13003      Southeast Region         YAZOO          Southern Mississippi   \n",
       "\n",
       "       gender zip_code        city state  \n",
       "0      Female    24910    ALDERSON    WV  \n",
       "1      Female    35442  ALICEVILLE    AL  \n",
       "2        Male    17810   ALLENWOOD    PA  \n",
       "3        Male    17810  WHITE DEER    PA  \n",
       "4        Male    17810   ALLENWOOD    PA  \n",
       "...       ...      ...         ...   ...  \n",
       "12999    Male    29590     SALTERS    SC  \n",
       "13000    Male    57078     YANKTON    SD  \n",
       "13001    Male    39194  YAZOO CITY    MS  \n",
       "13002    Male    39194  YAZOO CITY    MS  \n",
       "13003    Male    39194  YAZOO CITY    MS  \n",
       "\n",
       "[13003 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_address_components(data, 'full_address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_political_leaning = {\n",
    "    'AL': 'red', 'AK': 'red', 'AZ': 'purple', 'AR': 'red', 'CA': 'blue',\n",
    "    'CO': 'purple', 'CT': 'blue', 'DE': 'blue', 'FL': 'purple', 'GA': 'purple',\n",
    "    'HI': 'blue', 'ID': 'red', 'IL': 'blue', 'IN': 'red', 'IA': 'purple',\n",
    "    'KS': 'red', 'KY': 'red', 'LA': 'red', 'ME': 'purple', 'MD': 'blue',\n",
    "    'MA': 'blue', 'MI': 'purple', 'MN': 'blue', 'MS': 'red', 'MO': 'red',\n",
    "    'MT': 'red', 'NE': 'red', 'NV': 'purple', 'NH': 'purple', 'NJ': 'blue',\n",
    "    'NM': 'blue', 'NY': 'blue', 'NC': 'purple', 'ND': 'red', 'OH': 'purple',\n",
    "    'OK': 'red', 'OR': 'blue', 'PA': 'purple', 'RI': 'blue', 'SC': 'red',\n",
    "    'SD': 'red', 'TN': 'red', 'TX': 'purple', 'UT': 'red', 'VT': 'blue',\n",
    "    'VA': 'purple', 'WA': 'blue', 'WV': 'red', 'WI': 'purple', 'WY': 'red', 'PR':'red'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_political_affiliation(data, state_political_leaning):\n",
    "    # Create a new column for political affiliation with default value\n",
    "    data['political_affiliation'] = 'unknown'\n",
    "    \n",
    "    # Iterate over the DataFrame using the correct indices\n",
    "    for idx, row in data.iterrows():\n",
    "        state = row['state']\n",
    "        # Check if the state exists in the dictionary\n",
    "        if state in state_political_leaning:\n",
    "            data.at[idx, 'political_affiliation'] = state_political_leaning[state]\n",
    "        else:\n",
    "            print(f\"Warning: State abbreviation {state} at index {idx} not found in dictionary\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = add_political_affiliation(data, state_political_leaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '48769aa9d81c48038f572120240405'\n",
    "# Function to fetch temperature and precipitation data\n",
    "def fetch_temperature_data(df):\n",
    "    base_url = \"http://api.weatherapi.com/v1/history.json\"\n",
    "    \n",
    "    # Lists to store temperature and precipitation data\n",
    "    temperatures = []\n",
    "    precipitations = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        # Extract the date and location for the API call\n",
    "        date = row['datetime_of_data'].split(' ')[0] \n",
    "        location = row['zip_code'] \n",
    "\n",
    "        # Prepare the full URL for the API call\n",
    "        full_url = f\"{base_url}?key={api_key}&q={location}&dt={date}\"\n",
    "        \n",
    "        # Make the request to the WeatherAPI.com\n",
    "        response = requests.get(full_url)\n",
    "        print(response)\n",
    "        \n",
    "    #     if response.status_code == 200:\n",
    "    #         # Parse the response JSON\n",
    "    #         data = response.json()\n",
    "    #         # Extract temperature and precipitation\n",
    "    #         temperature = data['forecast']['forecastday'][0]['day']['avgtemp_f']\n",
    "    #         daily_precipitation = data['forecast']['forecastday'][0]['day']['totalprecip_mm']\n",
    "    #     else:\n",
    "    #         # In case of an API error, we append a None or error message\n",
    "    #         temperature = None\n",
    "    #         daily_precipitation = None\n",
    "    #         print(f\"Error fetching data for {location} on {date}: {response.status_code}\")\n",
    "        \n",
    "    #     # Append the results to the lists\n",
    "    #     temperatures.append(temperature)\n",
    "    #     precipitations.append(daily_precipitation)\n",
    "    \n",
    "    # # Add the temperature and precipitation data as columns to the DataFrame\n",
    "    # df['daily_temperature'] = temperatures\n",
    "    # df['daily_precipitation'] = precipitations\n",
    "    \n",
    "    # return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_temperature_data(df):\n",
    "    base_url = \"http://api.weatherapi.com/v1/history.json\"\n",
    "    api_key = '48769aa9d81c48038f572120240405'\n",
    "    temperatures = []\n",
    "    precipitations = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        date = row['datetime_of_data'].split(' ')[0]\n",
    "        location = row['zip_code']\n",
    "        full_url = f\"{base_url}?key={api_key}&q={location}&dt={date}\"\n",
    "        \n",
    "        print(\"Requesting:\", full_url)  # Debugging output\n",
    "        \n",
    "        response = requests.get(full_url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            temperature = data['forecast']['forecastday'][0]['day']['avgtemp_f']\n",
    "            daily_precipitation = data['forecast']['forecastday'][0]['day']['totalprecip_mm']\n",
    "        else:\n",
    "            print(f\"Error fetching data for {location} on {date}: {response.status_code}\")\n",
    "            temperature = None\n",
    "            daily_precipitation = None\n",
    "        \n",
    "        temperatures.append(temperature)\n",
    "        precipitations.append(daily_precipitation)\n",
    "    \n",
    "    df['daily_temperature'] = temperatures\n",
    "    df['daily_precipitation'] = precipitations\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=24910&dt=2024-03-25\n",
      "Error fetching data for 24910 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=35442&dt=2024-03-25\n",
      "Error fetching data for 35442 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=17810&dt=2024-03-25\n",
      "Error fetching data for 17810 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=17810&dt=2024-03-25\n",
      "Error fetching data for 17810 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=17810&dt=2024-03-25\n",
      "Error fetching data for 17810 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=41105&dt=2024-03-25\n",
      "Error fetching data for 41105 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=30315&dt=2024-03-25\n",
      "Error fetching data for 30315 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=95301&dt=2024-03-25\n",
      "Error fetching data for 95301 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=78602&dt=2024-03-25\n",
      "Error fetching data for 78602 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=77705&dt=2024-03-25\n",
      "Error fetching data for 77705 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=77705&dt=2024-03-25\n",
      "Error fetching data for 77705 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=77705&dt=2024-03-25\n",
      "Error fetching data for 77705 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=25813&dt=2024-03-25\n",
      "Error fetching data for 25813 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=29512&dt=2024-03-25\n",
      "Error fetching data for 29512 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=3570&dt=2024-03-25\n",
      "Error fetching data for 3570 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=41224&dt=2024-03-25\n",
      "Error fetching data for 41224 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=79720&dt=2024-03-25\n",
      "Error fetching data for 79720 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=11232&dt=2024-03-25\n",
      "Error fetching data for 11232 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=77803&dt=2024-03-25\n",
      "Error fetching data for 77803 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=27509&dt=2024-03-25\n",
      "Error fetching data for 27509 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=27509&dt=2024-03-25\n",
      "Error fetching data for 27509 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=27509&dt=2024-03-25\n",
      "Error fetching data for 27509 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=27509&dt=2024-03-25\n",
      "Error fetching data for 27509 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=18472&dt=2024-03-25\n",
      "Error fetching data for 18472 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=76127&dt=2024-03-25\n",
      "Error fetching data for 76127 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=60605&dt=2024-03-25\n",
      "Error fetching data for 60605 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=33521&dt=2024-03-25\n",
      "Error fetching data for 33521 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=33521&dt=2024-03-25\n",
      "Error fetching data for 33521 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=33521&dt=2024-03-25\n",
      "Error fetching data for 33521 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=33521&dt=2024-03-25\n",
      "Error fetching data for 33521 on 2024-03-25: 400\n",
      "Requesting: http://api.weatherapi.com/v1/history.json?key=48769aa9d81c48038f572120240405&q=21502&dt=2024-03-25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_temperature_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[82], line 16\u001b[0m, in \u001b[0;36mfetch_temperature_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     12\u001b[0m full_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?key=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&q=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&dt=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequesting:\u001b[39m\u001b[38;5;124m\"\u001b[39m, full_url)  \u001b[38;5;66;03m# Debugging output\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     18\u001b[0m     data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/anaconda3/envs/ACLU/lib/python3.9/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ACLU/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ACLU/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/ACLU/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/ACLU/lib/python3.9/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/anaconda3/envs/ACLU/lib/python3.9/site-packages/urllib3/connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    807\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ACLU/lib/python3.9/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/ACLU/lib/python3.9/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/anaconda3/envs/ACLU/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/ACLU/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ACLU/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ACLU/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = fetch_temperature_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/ianduke/Desktop/Defense_Data_Center\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprison_data_with_features.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/Users/ianduke/Desktop/Defense_Data_Center')\n",
    "data.to_csv('prison_data_with_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('prison_data_with_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lockdown Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "MCC NEW YORK           102\n",
       "USP CANAAN              81\n",
       "MDC GUAYNABO            73\n",
       "FCI MENDOTA             63\n",
       "USP FLORENCE - HIGH     55\n",
       "                      ... \n",
       "MCC New York             1\n",
       "FPC BRYAN                1\n",
       "FDC MIAMI                1\n",
       "FCI BERLIN               1\n",
       "FMC LEXINGTON            1\n",
       "Name: count, Length: 75, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suspended_data = data[data['visiting_status'] == 'Suspended']\n",
    "    \n",
    "counts = suspended_data['title'].value_counts()\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return % of time data indicates lockdown after a given date\n",
    "def suspension_count(data, facility, before):\n",
    "    filtered_df = data[data['datetime_of_data'] >= before]\n",
    "    filtered_df = filtered_df[filtered_df['title'] == facility]\n",
    "    suspended = filtered_df[filtered_df['visiting_status'] == 'Suspended']\n",
    "    count = len(suspended)\n",
    "    total = len(filtered_df)\n",
    "    return (count / total) * 100 if total > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.84848484848484"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suspension_count(data, 'USP CANAAN', '2024-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'population', 'operation_level', 'visiting_status',\n",
       "       'datetime_of_data', 'full_address', 'bop_region', 'county',\n",
       "       'judicial_district', 'gender', 'city', 'state', 'zip_code',\n",
       "       'political_affiliation', 'daily_high_temperature',\n",
       "       'daily_low_temperature', 'daily_precipitation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lockdown_percentage(facility_data):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of days a facility been locked down.\n",
    "    \"\"\"\n",
    "    # Drop rows where visiting_status is None\n",
    "    facility_data = facility_data.dropna(subset=['visiting_status'])\n",
    "    # Count the number of times the facility was locked down\n",
    "    lockdown_days = facility_data[facility_data['visiting_status'] == 'Suspended'].shape[0]\n",
    "    total_days = facility_data.shape[0]\n",
    "    if total_days > 0:\n",
    "        lockdown_perc = (lockdown_days / total_days) * 100\n",
    "    else:\n",
    "        lockdown_perc = 0\n",
    "    return lockdown_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "facility_name = data[\"title\"].unique()\n",
    "facility_percentage = {}\n",
    "for facility in facility_name:\n",
    "    facility_data = data[data['title'] == facility]\n",
    "    percentage = lockdown_percentage(facility_data)\n",
    "    facility_percentage[facility] = percentage\n",
    "facility_prob_df = pd.DataFrame(list(facility_percentage.items()), columns=[\"title\", \"lockdown_percentage\"])\n",
    "\n",
    "# Merge the new DataFrame add the new lockdown probabilities\n",
    "data_with_percent = pd.merge(data, facility_prob_df, on=\"title\", how=\"left\")\n",
    "data_with_percent\n",
    "facility_prob_df\n",
    "\n",
    "percentage_dict = {}\n",
    "\n",
    "for i in range(len(facility_prob_df)):\n",
    "    percentage_dict[facility_prob_df['title'][i]] = facility_prob_df['lockdown_percentage'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.64077669902912"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_dict['USP CANAAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_columns = ['population','title', 'visiting_status' ,'daily_high_temperature', 'daily_low_temperature', 'daily_precipitation', 'gender', 'political_affiliation', 'lockdown_percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>population</th>\n",
       "      <th>operation_level</th>\n",
       "      <th>visiting_status</th>\n",
       "      <th>datetime_of_data</th>\n",
       "      <th>full_address</th>\n",
       "      <th>bop_region</th>\n",
       "      <th>county</th>\n",
       "      <th>judicial_district</th>\n",
       "      <th>gender</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>political_affiliation</th>\n",
       "      <th>daily_high_temperature</th>\n",
       "      <th>daily_low_temperature</th>\n",
       "      <th>daily_precipitation</th>\n",
       "      <th>lockdown_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FPC ALDERSON</td>\n",
       "      <td>695</td>\n",
       "      <td>No Longer Available</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-03-25 19:34:07 PDT</td>\n",
       "      <td>GLEN RAY RD. BOX A, ALDERSON, WV 24910</td>\n",
       "      <td>Mid-Atlantic Region</td>\n",
       "      <td>GREENBRIER</td>\n",
       "      <td>Southern West Virginia</td>\n",
       "      <td>Female</td>\n",
       "      <td>ALDERSON</td>\n",
       "      <td>WV</td>\n",
       "      <td>24910</td>\n",
       "      <td>red</td>\n",
       "      <td>54.9</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FCI ALICEVILLE</td>\n",
       "      <td>1,569</td>\n",
       "      <td>No Longer Available</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-03-25 19:34:23 PDT</td>\n",
       "      <td>11070 HIGHWAY 14, ALICEVILLE, AL 35442</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>PICKENS</td>\n",
       "      <td>Northern District of Alabama</td>\n",
       "      <td>Female</td>\n",
       "      <td>ALICEVILLE</td>\n",
       "      <td>AL</td>\n",
       "      <td>35442</td>\n",
       "      <td>red</td>\n",
       "      <td>66.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FCI ALLENWOOD LOW</td>\n",
       "      <td>976</td>\n",
       "      <td>No Longer Available</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-03-25 19:34:38 PDT</td>\n",
       "      <td>RT 15,2 MILES N OF ALLENWOOD, ALLENWOOD, PA 17810</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>UNION</td>\n",
       "      <td>Middle Pennsylvania</td>\n",
       "      <td>Male</td>\n",
       "      <td>ALLENWOOD</td>\n",
       "      <td>PA</td>\n",
       "      <td>17810</td>\n",
       "      <td>purple</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.766990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FCI ALLENWOOD MEDIUM</td>\n",
       "      <td>1,272</td>\n",
       "      <td>No Longer Available</td>\n",
       "      <td>Suspended</td>\n",
       "      <td>2024-03-25 19:34:54 PDT</td>\n",
       "      <td>RT 15, 2 MI N OF ALLENWOOD, WHITE DEER, PA 17810</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>Union</td>\n",
       "      <td>Middle Pennsylvania</td>\n",
       "      <td>Male</td>\n",
       "      <td>WHITE DEER</td>\n",
       "      <td>PA</td>\n",
       "      <td>17810</td>\n",
       "      <td>purple</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.922330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USP ALLENWOOD</td>\n",
       "      <td>282</td>\n",
       "      <td>No Longer Available</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2024-03-25 19:35:09 PDT</td>\n",
       "      <td>RT 15,2 MILES N OF ALLENWOOD, ALLENWOOD, PA 17810</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>Union</td>\n",
       "      <td>Middle Pennsylvania</td>\n",
       "      <td>Male</td>\n",
       "      <td>ALLENWOOD</td>\n",
       "      <td>PA</td>\n",
       "      <td>17810</td>\n",
       "      <td>purple</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12559</th>\n",
       "      <td>FCI WILLIAMSBURG</td>\n",
       "      <td>1,409</td>\n",
       "      <td>Level 1</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2023-11-13 09:52:01 PST</td>\n",
       "      <td>8301 HIGHWAY 521, SALTERS, SC 29590</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Male</td>\n",
       "      <td>SALTERS</td>\n",
       "      <td>SC</td>\n",
       "      <td>29590</td>\n",
       "      <td>red</td>\n",
       "      <td>63.9</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12560</th>\n",
       "      <td>FPC YANKTON</td>\n",
       "      <td>410</td>\n",
       "      <td>Level 1</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2023-11-13 09:52:17 PST</td>\n",
       "      <td>1016 DOUGLAS AVENUE, YANKTON, SD 57078</td>\n",
       "      <td>North Central Region</td>\n",
       "      <td>Yankton</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>Male</td>\n",
       "      <td>YANKTON</td>\n",
       "      <td>SD</td>\n",
       "      <td>57078</td>\n",
       "      <td>red</td>\n",
       "      <td>63.7</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12561</th>\n",
       "      <td>FCI YAZOO CITY MEDIUM</td>\n",
       "      <td>1,439</td>\n",
       "      <td>Level 1</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2023-11-13 09:52:33 PST</td>\n",
       "      <td>2225 HALEY BARBOUR PARKWAY, YAZOO CITY, MS 39194</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>YAZOO</td>\n",
       "      <td>Southern Mississippi</td>\n",
       "      <td>Male</td>\n",
       "      <td>YAZOO CITY</td>\n",
       "      <td>MS</td>\n",
       "      <td>39194</td>\n",
       "      <td>red</td>\n",
       "      <td>72.8</td>\n",
       "      <td>55.9</td>\n",
       "      <td>0.04</td>\n",
       "      <td>19.417476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12562</th>\n",
       "      <td>FCI YAZOO CITY LOW</td>\n",
       "      <td>1,487</td>\n",
       "      <td>Level 1</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2023-11-13 09:52:49 PST</td>\n",
       "      <td>2225 HALEY BARBOUR PARKWAY, YAZOO CITY, MS 39194</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>YAZOO</td>\n",
       "      <td>Southern Mississippi</td>\n",
       "      <td>Male</td>\n",
       "      <td>YAZOO CITY</td>\n",
       "      <td>MS</td>\n",
       "      <td>39194</td>\n",
       "      <td>red</td>\n",
       "      <td>72.8</td>\n",
       "      <td>55.9</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12563</th>\n",
       "      <td>USP YAZOO CITY</td>\n",
       "      <td>1,502</td>\n",
       "      <td>Level 1</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>2023-11-13 09:53:05 PST</td>\n",
       "      <td>2225 HALEY BARBOUR PKWY, YAZOO CITY, MS 39194</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>YAZOO</td>\n",
       "      <td>Southern Mississippi</td>\n",
       "      <td>Male</td>\n",
       "      <td>YAZOO CITY</td>\n",
       "      <td>MS</td>\n",
       "      <td>39194</td>\n",
       "      <td>red</td>\n",
       "      <td>72.8</td>\n",
       "      <td>55.9</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12564 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title population      operation_level visiting_status  \\\n",
       "0               FPC ALDERSON        695  No Longer Available   Not Suspended   \n",
       "1             FCI ALICEVILLE      1,569  No Longer Available   Not Suspended   \n",
       "2          FCI ALLENWOOD LOW        976  No Longer Available   Not Suspended   \n",
       "3       FCI ALLENWOOD MEDIUM      1,272  No Longer Available       Suspended   \n",
       "4              USP ALLENWOOD        282  No Longer Available   Not Suspended   \n",
       "...                      ...        ...                  ...             ...   \n",
       "12559       FCI WILLIAMSBURG      1,409              Level 1   Not Suspended   \n",
       "12560            FPC YANKTON        410              Level 1   Not Suspended   \n",
       "12561  FCI YAZOO CITY MEDIUM      1,439              Level 1   Not Suspended   \n",
       "12562     FCI YAZOO CITY LOW      1,487              Level 1   Not Suspended   \n",
       "12563         USP YAZOO CITY      1,502              Level 1   Not Suspended   \n",
       "\n",
       "              datetime_of_data  \\\n",
       "0      2024-03-25 19:34:07 PDT   \n",
       "1      2024-03-25 19:34:23 PDT   \n",
       "2      2024-03-25 19:34:38 PDT   \n",
       "3      2024-03-25 19:34:54 PDT   \n",
       "4      2024-03-25 19:35:09 PDT   \n",
       "...                        ...   \n",
       "12559  2023-11-13 09:52:01 PST   \n",
       "12560  2023-11-13 09:52:17 PST   \n",
       "12561  2023-11-13 09:52:33 PST   \n",
       "12562  2023-11-13 09:52:49 PST   \n",
       "12563  2023-11-13 09:53:05 PST   \n",
       "\n",
       "                                            full_address  \\\n",
       "0                 GLEN RAY RD. BOX A, ALDERSON, WV 24910   \n",
       "1                 11070 HIGHWAY 14, ALICEVILLE, AL 35442   \n",
       "2      RT 15,2 MILES N OF ALLENWOOD, ALLENWOOD, PA 17810   \n",
       "3       RT 15, 2 MI N OF ALLENWOOD, WHITE DEER, PA 17810   \n",
       "4      RT 15,2 MILES N OF ALLENWOOD, ALLENWOOD, PA 17810   \n",
       "...                                                  ...   \n",
       "12559                8301 HIGHWAY 521, SALTERS, SC 29590   \n",
       "12560             1016 DOUGLAS AVENUE, YANKTON, SD 57078   \n",
       "12561   2225 HALEY BARBOUR PARKWAY, YAZOO CITY, MS 39194   \n",
       "12562   2225 HALEY BARBOUR PARKWAY, YAZOO CITY, MS 39194   \n",
       "12563      2225 HALEY BARBOUR PKWY, YAZOO CITY, MS 39194   \n",
       "\n",
       "                 bop_region        county             judicial_district  \\\n",
       "0       Mid-Atlantic Region    GREENBRIER        Southern West Virginia   \n",
       "1          Southeast Region       PICKENS  Northern District of Alabama   \n",
       "2          Northeast Region         UNION           Middle Pennsylvania   \n",
       "3          Northeast Region         Union           Middle Pennsylvania   \n",
       "4          Northeast Region         Union           Middle Pennsylvania   \n",
       "...                     ...           ...                           ...   \n",
       "12559      Southeast Region  Williamsburg                South Carolina   \n",
       "12560  North Central Region       Yankton                  South Dakota   \n",
       "12561      Southeast Region         YAZOO          Southern Mississippi   \n",
       "12562      Southeast Region         YAZOO          Southern Mississippi   \n",
       "12563      Southeast Region         YAZOO          Southern Mississippi   \n",
       "\n",
       "       gender        city state  zip_code political_affiliation  \\\n",
       "0      Female    ALDERSON    WV     24910                   red   \n",
       "1      Female  ALICEVILLE    AL     35442                   red   \n",
       "2        Male   ALLENWOOD    PA     17810                purple   \n",
       "3        Male  WHITE DEER    PA     17810                purple   \n",
       "4        Male   ALLENWOOD    PA     17810                purple   \n",
       "...       ...         ...   ...       ...                   ...   \n",
       "12559    Male     SALTERS    SC     29590                   red   \n",
       "12560    Male     YANKTON    SD     57078                   red   \n",
       "12561    Male  YAZOO CITY    MS     39194                   red   \n",
       "12562    Male  YAZOO CITY    MS     39194                   red   \n",
       "12563    Male  YAZOO CITY    MS     39194                   red   \n",
       "\n",
       "       daily_high_temperature  daily_low_temperature  daily_precipitation  \\\n",
       "0                        54.9                   29.5                 0.00   \n",
       "1                        66.0                   53.0                 0.84   \n",
       "2                        52.0                   25.2                 0.00   \n",
       "3                        52.0                   25.2                 0.00   \n",
       "4                        52.0                   25.2                 0.00   \n",
       "...                       ...                    ...                  ...   \n",
       "12559                    63.9                   45.9                 0.00   \n",
       "12560                    63.7                   33.1                 0.00   \n",
       "12561                    72.8                   55.9                 0.04   \n",
       "12562                    72.8                   55.9                 0.04   \n",
       "12563                    72.8                   55.9                 0.04   \n",
       "\n",
       "       lockdown_percentage  \n",
       "0                 0.000000  \n",
       "1                 0.000000  \n",
       "2                 7.766990  \n",
       "3                35.922330  \n",
       "4                 0.000000  \n",
       "...                    ...  \n",
       "12559             0.000000  \n",
       "12560             0.000000  \n",
       "12561            19.417476  \n",
       "12562             0.000000  \n",
       "12563             0.000000  \n",
       "\n",
       "[12564 rows x 18 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data = data_with_percent[modeling_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>title</th>\n",
       "      <th>visiting_status</th>\n",
       "      <th>daily_high_temperature</th>\n",
       "      <th>daily_low_temperature</th>\n",
       "      <th>daily_precipitation</th>\n",
       "      <th>gender</th>\n",
       "      <th>political_affiliation</th>\n",
       "      <th>lockdown_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>695</td>\n",
       "      <td>FPC ALDERSON</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>54.9</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>red</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,569</td>\n",
       "      <td>FCI ALICEVILLE</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>66.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>Female</td>\n",
       "      <td>red</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>976</td>\n",
       "      <td>FCI ALLENWOOD LOW</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>purple</td>\n",
       "      <td>7.766990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,272</td>\n",
       "      <td>FCI ALLENWOOD MEDIUM</td>\n",
       "      <td>Suspended</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>purple</td>\n",
       "      <td>35.922330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>282</td>\n",
       "      <td>USP ALLENWOOD</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>purple</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12559</th>\n",
       "      <td>1,409</td>\n",
       "      <td>FCI WILLIAMSBURG</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>63.9</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>red</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12560</th>\n",
       "      <td>410</td>\n",
       "      <td>FPC YANKTON</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>63.7</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>red</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12561</th>\n",
       "      <td>1,439</td>\n",
       "      <td>FCI YAZOO CITY MEDIUM</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>72.8</td>\n",
       "      <td>55.9</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Male</td>\n",
       "      <td>red</td>\n",
       "      <td>19.417476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12562</th>\n",
       "      <td>1,487</td>\n",
       "      <td>FCI YAZOO CITY LOW</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>72.8</td>\n",
       "      <td>55.9</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Male</td>\n",
       "      <td>red</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12563</th>\n",
       "      <td>1,502</td>\n",
       "      <td>USP YAZOO CITY</td>\n",
       "      <td>Not Suspended</td>\n",
       "      <td>72.8</td>\n",
       "      <td>55.9</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Male</td>\n",
       "      <td>red</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12564 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      population                  title visiting_status  \\\n",
       "0            695           FPC ALDERSON   Not Suspended   \n",
       "1          1,569         FCI ALICEVILLE   Not Suspended   \n",
       "2            976      FCI ALLENWOOD LOW   Not Suspended   \n",
       "3          1,272   FCI ALLENWOOD MEDIUM       Suspended   \n",
       "4            282          USP ALLENWOOD   Not Suspended   \n",
       "...          ...                    ...             ...   \n",
       "12559      1,409       FCI WILLIAMSBURG   Not Suspended   \n",
       "12560        410            FPC YANKTON   Not Suspended   \n",
       "12561      1,439  FCI YAZOO CITY MEDIUM   Not Suspended   \n",
       "12562      1,487     FCI YAZOO CITY LOW   Not Suspended   \n",
       "12563      1,502         USP YAZOO CITY   Not Suspended   \n",
       "\n",
       "       daily_high_temperature  daily_low_temperature  daily_precipitation  \\\n",
       "0                        54.9                   29.5                 0.00   \n",
       "1                        66.0                   53.0                 0.84   \n",
       "2                        52.0                   25.2                 0.00   \n",
       "3                        52.0                   25.2                 0.00   \n",
       "4                        52.0                   25.2                 0.00   \n",
       "...                       ...                    ...                  ...   \n",
       "12559                    63.9                   45.9                 0.00   \n",
       "12560                    63.7                   33.1                 0.00   \n",
       "12561                    72.8                   55.9                 0.04   \n",
       "12562                    72.8                   55.9                 0.04   \n",
       "12563                    72.8                   55.9                 0.04   \n",
       "\n",
       "       gender political_affiliation  lockdown_percentage  \n",
       "0      Female                   red             0.000000  \n",
       "1      Female                   red             0.000000  \n",
       "2        Male                purple             7.766990  \n",
       "3        Male                purple            35.922330  \n",
       "4        Male                purple             0.000000  \n",
       "...       ...                   ...                  ...  \n",
       "12559    Male                   red             0.000000  \n",
       "12560    Male                   red             0.000000  \n",
       "12561    Male                   red            19.417476  \n",
       "12562    Male                   red             0.000000  \n",
       "12563    Male                   red             0.000000  \n",
       "\n",
       "[12564 rows x 9 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population    48\n",
      "gender        21\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NA values in each column and count them\n",
    "na_columns = modeling_data.isna().sum()\n",
    "\n",
    "# Print columns with missing values and their counts\n",
    "print(na_columns[na_columns > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first remove rows in which population or gender is empty (scraping error)\n",
    "modeling_data = modeling_data.dropna(subset=['population'])\n",
    "modeling_data = modeling_data.dropna(subset=['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find rows with any NA values\n",
    "rows_with_na = modeling_data[modeling_data.isna().any(axis=1)]\n",
    "\n",
    "# Display these rows\n",
    "rows_with_na['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix USP THOMSON and MCC New York\n",
    "modeling_data.loc[modeling_data['title'] == 'USP THOMSON', 'bop_region'] = 'North Central Region'\n",
    "modeling_data.loc[modeling_data['title'] == 'MCC New York', 'bop_region'] = 'Northeast Region'\n",
    "\n",
    "modeling_data.loc[modeling_data['title'] == 'USP THOMSON', 'gender'] = 'Male'\n",
    "modeling_data.loc[modeling_data['title'] == 'MCC New York', 'gender'] = 'Male'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find rows with any NA values\n",
    "rows_with_na = modeling_data[modeling_data.isna().any(axis=1)]\n",
    "\n",
    "# Display these rows\n",
    "rows_with_na['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data = modeling_data[modeling_data['title'] != 'MCC New York']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>title</th>\n",
       "      <th>daily_high_temperature</th>\n",
       "      <th>daily_low_temperature</th>\n",
       "      <th>daily_precipitation</th>\n",
       "      <th>lockdown_percentage</th>\n",
       "      <th>visiting_status_Suspended</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Male and Female</th>\n",
       "      <th>political_affiliation_purple</th>\n",
       "      <th>political_affiliation_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>695</td>\n",
       "      <td>FPC ALDERSON</td>\n",
       "      <td>54.9</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,569</td>\n",
       "      <td>FCI ALICEVILLE</td>\n",
       "      <td>66.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>976</td>\n",
       "      <td>FCI ALLENWOOD LOW</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.76699</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,272</td>\n",
       "      <td>FCI ALLENWOOD MEDIUM</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.92233</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>282</td>\n",
       "      <td>USP ALLENWOOD</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  population                 title  daily_high_temperature  \\\n",
       "0        695          FPC ALDERSON                    54.9   \n",
       "1      1,569        FCI ALICEVILLE                    66.0   \n",
       "2        976     FCI ALLENWOOD LOW                    52.0   \n",
       "3      1,272  FCI ALLENWOOD MEDIUM                    52.0   \n",
       "4        282         USP ALLENWOOD                    52.0   \n",
       "\n",
       "   daily_low_temperature  daily_precipitation  lockdown_percentage  \\\n",
       "0                   29.5                 0.00              0.00000   \n",
       "1                   53.0                 0.84              0.00000   \n",
       "2                   25.2                 0.00              7.76699   \n",
       "3                   25.2                 0.00             35.92233   \n",
       "4                   25.2                 0.00              0.00000   \n",
       "\n",
       "   visiting_status_Suspended  gender_Male  gender_Male and Female  \\\n",
       "0                          0            0                       0   \n",
       "1                          0            0                       0   \n",
       "2                          0            1                       0   \n",
       "3                          1            1                       0   \n",
       "4                          0            1                       0   \n",
       "\n",
       "   political_affiliation_purple  political_affiliation_red  \n",
       "0                             0                          1  \n",
       "1                             0                          1  \n",
       "2                             1                          0  \n",
       "3                             1                          0  \n",
       "4                             1                          0  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy encode the specified columns\n",
    "dummy_columns = ['visiting_status', 'gender', 'political_affiliation']\n",
    "modeling_data_encoded = pd.get_dummies(modeling_data, columns=dummy_columns, drop_first=True, dtype = int)\n",
    "\n",
    "# View the resulting DataFrame\n",
    "modeling_data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data_encoded = modeling_data_encoded.drop('title', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>daily_high_temperature</th>\n",
       "      <th>daily_low_temperature</th>\n",
       "      <th>daily_precipitation</th>\n",
       "      <th>lockdown_percentage</th>\n",
       "      <th>visiting_status_Suspended</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Male and Female</th>\n",
       "      <th>political_affiliation_purple</th>\n",
       "      <th>political_affiliation_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>695</td>\n",
       "      <td>54.9</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,569</td>\n",
       "      <td>66.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>976</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.766990</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,272</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.922330</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>282</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12559</th>\n",
       "      <td>1,409</td>\n",
       "      <td>63.9</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12560</th>\n",
       "      <td>410</td>\n",
       "      <td>63.7</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12561</th>\n",
       "      <td>1,439</td>\n",
       "      <td>72.8</td>\n",
       "      <td>55.9</td>\n",
       "      <td>0.04</td>\n",
       "      <td>19.417476</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12562</th>\n",
       "      <td>1,487</td>\n",
       "      <td>72.8</td>\n",
       "      <td>55.9</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12563</th>\n",
       "      <td>1,502</td>\n",
       "      <td>72.8</td>\n",
       "      <td>55.9</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12495 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      population  daily_high_temperature  daily_low_temperature  \\\n",
       "0            695                    54.9                   29.5   \n",
       "1          1,569                    66.0                   53.0   \n",
       "2            976                    52.0                   25.2   \n",
       "3          1,272                    52.0                   25.2   \n",
       "4            282                    52.0                   25.2   \n",
       "...          ...                     ...                    ...   \n",
       "12559      1,409                    63.9                   45.9   \n",
       "12560        410                    63.7                   33.1   \n",
       "12561      1,439                    72.8                   55.9   \n",
       "12562      1,487                    72.8                   55.9   \n",
       "12563      1,502                    72.8                   55.9   \n",
       "\n",
       "       daily_precipitation  lockdown_percentage  visiting_status_Suspended  \\\n",
       "0                     0.00             0.000000                          0   \n",
       "1                     0.84             0.000000                          0   \n",
       "2                     0.00             7.766990                          0   \n",
       "3                     0.00            35.922330                          1   \n",
       "4                     0.00             0.000000                          0   \n",
       "...                    ...                  ...                        ...   \n",
       "12559                 0.00             0.000000                          0   \n",
       "12560                 0.00             0.000000                          0   \n",
       "12561                 0.04            19.417476                          0   \n",
       "12562                 0.04             0.000000                          0   \n",
       "12563                 0.04             0.000000                          0   \n",
       "\n",
       "       gender_Male  gender_Male and Female  political_affiliation_purple  \\\n",
       "0                0                       0                             0   \n",
       "1                0                       0                             0   \n",
       "2                1                       0                             1   \n",
       "3                1                       0                             1   \n",
       "4                1                       0                             1   \n",
       "...            ...                     ...                           ...   \n",
       "12559            1                       0                             0   \n",
       "12560            1                       0                             0   \n",
       "12561            1                       0                             0   \n",
       "12562            1                       0                             0   \n",
       "12563            1                       0                             0   \n",
       "\n",
       "       political_affiliation_red  \n",
       "0                              1  \n",
       "1                              1  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  \n",
       "...                          ...  \n",
       "12559                          1  \n",
       "12560                          1  \n",
       "12561                          1  \n",
       "12562                          1  \n",
       "12563                          1  \n",
       "\n",
       "[12495 rows x 10 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in modeling_data_encoded.columns:\n",
    "    # Check if the column's data type is object and if it contains commas\n",
    "    if modeling_data_encoded[column].dtype == 'object' and modeling_data_encoded[column].str.contains(',').any():\n",
    "        modeling_data_encoded[column] = modeling_data_encoded[column].str.replace(',', '').astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = modeling_data_encoded.drop('visiting_status_Suspended', axis = 1)\n",
    "y = modeling_data_encoded['visiting_status_Suspended']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state =13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('x_train.csv', index = False)\n",
    "# first let's rescale our data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the data and transform it\n",
    "x_train_sc_array = scaler.fit_transform(X_train)\n",
    "x_test_sc_array = scaler.transform(X_test)\n",
    "\n",
    "# Convert the scaled array back to a DataFrame\n",
    "x_train_sc = pd.DataFrame(x_train_sc_array, columns=X_train.columns)\n",
    "x_test_sc = pd.DataFrame(x_test_sc_array, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sc.to_csv('/Users/ianduke/Desktop/prison/data_update/training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's write a loop that selects only features that are most frequently relevant across different train/test splits\n",
    "relevant_features = []\n",
    "for _ in range(100):\n",
    "    # Train test split\n",
    "    X_loop = modeling_data_encoded.drop('visiting_status_Suspended', axis = 1)\n",
    "    y_loop = modeling_data_encoded['visiting_status_Suspended']\n",
    "\n",
    "    X_train_loop, X_test_loop, y_train_loop, y_test_loop = train_test_split(X_loop, y_loop, test_size=0.25, random_state =13)\n",
    "\n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    x_train_sc_array = scaler.fit_transform(X_train_loop)\n",
    "    x_train_sc_loop = pd.DataFrame(x_train_sc_array, columns=X_train_loop.columns)\n",
    "\n",
    "    # Fit the logistic regression model with L1 regularization\n",
    "    model = LogisticRegression(penalty='l1', solver='liblinear')  # 'liblinear' solver supports L1 penalty\n",
    "    model.fit(x_train_sc_loop, y_train_loop)\n",
    "\n",
    "    # Get indices of non-zero coefficients\n",
    "    non_zero_indices = [i for i, coef in enumerate(model.coef_.flatten()) if coef != 0]\n",
    "\n",
    "    # Map indices to column names\n",
    "    selected_feature_names = x_train_sc_loop.columns[non_zero_indices]\n",
    "\n",
    "    temporary_list = selected_feature_names.tolist()\n",
    "\n",
    "    relevant_features += temporary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daily_high_temperature',\n",
       " 'daily_low_temperature',\n",
       " 'daily_precipitation',\n",
       " 'gender_Male',\n",
       " 'gender_Male and Female',\n",
       " 'lockdown_percentage',\n",
       " 'political_affiliation_purple',\n",
       " 'political_affiliation_red',\n",
       " 'population']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.DataFrame(relevant_features).value_counts()\n",
    "x = x.reset_index()\n",
    "significant_features = list(x[0])\n",
    "significant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daily_high_temperature</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daily_low_temperature</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>daily_precipitation</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gender_Male</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gender_Male and Female</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lockdown_percentage</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>political_affiliation_purple</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>political_affiliation_red</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>population</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0  count\n",
       "0        daily_high_temperature    100\n",
       "1         daily_low_temperature    100\n",
       "2           daily_precipitation    100\n",
       "3                   gender_Male    100\n",
       "4        gender_Male and Female    100\n",
       "5           lockdown_percentage    100\n",
       "6  political_affiliation_purple    100\n",
       "7     political_affiliation_red    100\n",
       "8                    population    100"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features are predictive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for only time_sensitive columns\n",
    "time_cols =e ['daily_high_temperature','daily_low_temperature', 'daily_precipitation', 'population','lockdown_percentage']\n",
    "\n",
    "X_time = modeling_data_encoded.drop('visiting_status_Suspended', axis = 1)\n",
    "X_time = X_time[time_cols]\n",
    "\n",
    "X_train_time, X_test_time, y_train_time, y_test_time = train_test_split(X_time, y, test_size=0.25, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's rescale our data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the data and transform it\n",
    "x_train_sc_time_array = scaler.fit_transform(X_train_time)\n",
    "x_test_sc_time_array = scaler.transform(X_test_time)\n",
    "\n",
    "# Convert the scaled array back to a DataFrame\n",
    "x_train_time_sc = pd.DataFrame(x_train_sc_time_array, columns=X_train_time.columns)\n",
    "x_test_time_sc = pd.DataFrame(x_test_sc_time_array, columns=X_test_time.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic_and_find_best_score(X_train: pd.DataFrame, \n",
    "                                     y_train,\n",
    "                                     alphas: np.array = [1e-3, 1e-2, 1e-1, 1, 5, 10],\n",
    "                                     n_splits: int = 10,\n",
    "                                     random_state: int = 42) -> dict:\n",
    "    best_model = None\n",
    "    best_alpha = alphas[0]\n",
    "    best_recall = 0\n",
    "    best_accuracy = 0\n",
    "    best_precision = 0\n",
    "    best_coefficients = None\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for alpha in alphas:\n",
    "        fold_accuracies = []\n",
    "        fold_precisions = []\n",
    "        fold_recalls = []\n",
    "        \n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_train_fold_norm = scaler.fit_transform(X_train_fold)\n",
    "            X_val_fold_norm = scaler.transform(X_val_fold)\n",
    "            \n",
    "            model = LogisticRegression(penalty='l1', C=1/alpha, solver='liblinear', random_state=random_state, class_weight='balanced', max_iter=1000)\n",
    "            model.fit(X_train_fold_norm, y_train_fold)\n",
    "            predictions = model.predict(X_val_fold_norm)\n",
    "            \n",
    "            fold_accuracies.append(accuracy_score(y_val_fold, predictions))\n",
    "            fold_precisions.append(precision_score(y_val_fold, predictions, zero_division=0))\n",
    "            fold_recalls.append(recall_score(y_val_fold, predictions, zero_division=1))\n",
    "\n",
    "        # After calculating fold_accuracies, fold_precisions, and fold_recalls\n",
    "        mean_accuracy = np.mean(fold_accuracies)\n",
    "        mean_precision = np.mean(fold_precisions)\n",
    "        mean_recall = np.mean(fold_recalls)\n",
    "\n",
    "        # Then use these mean values to determine if the current model is the best\n",
    "        if mean_accuracy > best_accuracy:\n",
    "            best_model = model\n",
    "            best_alpha = alpha\n",
    "            best_recall = mean_recall\n",
    "            best_accuracy = mean_accuracy\n",
    "            best_precision = mean_precision\n",
    "            best_coefficients = model.coef_[0]\n",
    "\n",
    "    # Save the best model to a file\n",
    "    with open('best_logistic_model.pkl', 'wb') as file:\n",
    "        pickle.dump(best_model, file)\n",
    "\n",
    "    # Combine feature names with coefficients\n",
    "    feature_coeff_tuples = list(zip(X_train.columns, best_coefficients))\n",
    "\n",
    "    return {\n",
    "        'best_alpha': best_alpha,\n",
    "        'best_accuracy': best_accuracy,\n",
    "        'best_precision': best_precision,\n",
    "        'best_recall': best_recall,\n",
    "        'feature_coefficients': feature_coeff_tuples\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_alpha': 5,\n",
       " 'best_accuracy': 0.8323549958698655,\n",
       " 'best_precision': 0.3788860878376022,\n",
       " 'best_recall': 0.7667173821218127,\n",
       " 'feature_coefficients': [('population', 0.2401805812445803),\n",
       "  ('daily_high_temperature', -0.01757708056461793),\n",
       "  ('daily_low_temperature', -0.138675071391368),\n",
       "  ('daily_precipitation', 0.11564245743363075),\n",
       "  ('lockdown_percentage', 1.677826381923474),\n",
       "  ('gender_Male', 0.5504717781464566),\n",
       "  ('gender_Male and Female', 0.504248881281532),\n",
       "  ('political_affiliation_purple', -0.08336932708604741),\n",
       "  ('political_affiliation_red', -0.03231622519209802)]}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reset_index(drop = True, inplace = True)\n",
    "best_model_info_L1 = fit_logistic_and_find_best_score(x_train_sc, y_train)\n",
    "best_model_info_L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_alpha': 0.001,\n",
       " 'best_accuracy': 0.44274973660436945,\n",
       " 'best_precision': 0.10716182279780465,\n",
       " 'best_recall': 0.537751324101016,\n",
       " 'feature_coefficients': [('daily_high_temperature', 0.03555145695775357),\n",
       "  ('daily_low_temperature', -0.00835831599118456),\n",
       "  ('daily_precipitation', -0.011199545816865794),\n",
       "  ('population', 0.00956496877849458),\n",
       "  ('lockdown_percentage', -0.013745809415209715)]}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reset_index(drop = True, inplace = True)\n",
    "best_model_info_L1_time = fit_logistic_and_find_best_score(x_train_time_sc, y_train)\n",
    "best_model_info_L1_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "def fit_RF_and_find_best_score(X_train: pd.DataFrame, y_train, \n",
    "                               n_splits: int = 10, random_state: int = 42) -> dict:\n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "\n",
    "    # KFold cross-validation setup\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        # Split data\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Standardization\n",
    "        scaler = StandardScaler()\n",
    "        X_train_fold_norm = scaler.fit_transform(X_train_fold)\n",
    "        X_val_fold_norm = scaler.transform(X_val_fold)\n",
    "\n",
    "        # Train Random Forest\n",
    "        model = RandomForestClassifier(n_estimators=1000, random_state=random_state)\n",
    "        model.fit(X_train_fold_norm, y_train_fold)\n",
    "\n",
    "        # Prediction and scoring\n",
    "        predictions = model.predict(X_val_fold_norm)\n",
    "        accuracy = accuracy_score(y_val_fold, predictions)\n",
    "        precision = precision_score(y_val_fold, predictions, zero_division=0)\n",
    "        recall = recall_score(y_val_fold, predictions, zero_division=1)\n",
    "\n",
    "        # Update best model if current model is better\n",
    "        if accuracy > best_accuracy:\n",
    "            best_model = model\n",
    "            best_accuracy = accuracy\n",
    "            best_precision = precision\n",
    "            best_recall = recall\n",
    "\n",
    "    # Save the best model to a file\n",
    "    if best_model is not None:\n",
    "        with open('best_random_forest_model.pkl', 'wb') as file:\n",
    "            pickle.dump(best_model, file)\n",
    "\n",
    "        # Feature importances from the best model\n",
    "        feature_importances = best_model.feature_importances_\n",
    "\n",
    "        return {\n",
    "            'best_accuracy': best_accuracy,\n",
    "            'best_precision': best_precision,\n",
    "            'best_recall': best_recall,\n",
    "            'feature_importances': list(zip(X_train.columns, feature_importances))\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'best_accuracy': best_accuracy,\n",
    "            'best_precision': best_precision,\n",
    "            'best_recall': best_recall,\n",
    "            'feature_importances': []\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_accuracy': 0.9413020277481323,\n",
       " 'best_precision': 0.8648648648648649,\n",
       " 'best_recall': 0.5871559633027523,\n",
       " 'feature_importances': [('population', 0.25784377610004167),\n",
       "  ('daily_high_temperature', 0.1652817130699615),\n",
       "  ('daily_low_temperature', 0.15856606107973406),\n",
       "  ('daily_precipitation', 0.0846012533492087),\n",
       "  ('lockdown_percentage', 0.30723892602166875),\n",
       "  ('gender_Male', 0.004398106092940541),\n",
       "  ('gender_Male and Female', 0.0034094452563652837),\n",
       "  ('political_affiliation_purple', 0.009910179896956117),\n",
       "  ('political_affiliation_red', 0.008750539133123361)]}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reset_index(drop = True, inplace = True)\n",
    "best_model_info_rf = fit_RF_and_find_best_score(x_train_sc, y_train)\n",
    "best_model_info_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>daily_high_temperature</th>\n",
       "      <th>daily_low_temperature</th>\n",
       "      <th>daily_precipitation</th>\n",
       "      <th>lockdown_percentage</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Male and Female</th>\n",
       "      <th>political_affiliation_purple</th>\n",
       "      <th>political_affiliation_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019537</td>\n",
       "      <td>1.757667</td>\n",
       "      <td>2.411243</td>\n",
       "      <td>0.545476</td>\n",
       "      <td>3.359580</td>\n",
       "      <td>-1.889767</td>\n",
       "      <td>2.193096</td>\n",
       "      <td>-0.862983</td>\n",
       "      <td>1.524929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.440036</td>\n",
       "      <td>-0.111259</td>\n",
       "      <td>-0.442828</td>\n",
       "      <td>-0.371269</td>\n",
       "      <td>0.463050</td>\n",
       "      <td>0.529166</td>\n",
       "      <td>-0.455976</td>\n",
       "      <td>-0.862983</td>\n",
       "      <td>1.524929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.457680</td>\n",
       "      <td>-0.751302</td>\n",
       "      <td>-0.498517</td>\n",
       "      <td>-0.252009</td>\n",
       "      <td>-0.247420</td>\n",
       "      <td>-1.889767</td>\n",
       "      <td>2.193096</td>\n",
       "      <td>-0.862983</td>\n",
       "      <td>-0.655768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.532001</td>\n",
       "      <td>-1.064923</td>\n",
       "      <td>-0.630779</td>\n",
       "      <td>-0.362972</td>\n",
       "      <td>-0.629980</td>\n",
       "      <td>0.529166</td>\n",
       "      <td>-0.455976</td>\n",
       "      <td>1.158771</td>\n",
       "      <td>-0.655768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.627211</td>\n",
       "      <td>0.554386</td>\n",
       "      <td>-0.032120</td>\n",
       "      <td>-0.361935</td>\n",
       "      <td>0.408398</td>\n",
       "      <td>0.529166</td>\n",
       "      <td>-0.455976</td>\n",
       "      <td>1.158771</td>\n",
       "      <td>-0.655768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9366</th>\n",
       "      <td>0.911385</td>\n",
       "      <td>-1.071323</td>\n",
       "      <td>-0.916186</td>\n",
       "      <td>0.199104</td>\n",
       "      <td>1.173520</td>\n",
       "      <td>0.529166</td>\n",
       "      <td>-0.455976</td>\n",
       "      <td>-0.862983</td>\n",
       "      <td>1.524929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9367</th>\n",
       "      <td>0.739274</td>\n",
       "      <td>0.016750</td>\n",
       "      <td>-0.428906</td>\n",
       "      <td>-0.371269</td>\n",
       "      <td>-0.356723</td>\n",
       "      <td>0.529166</td>\n",
       "      <td>-0.455976</td>\n",
       "      <td>-0.862983</td>\n",
       "      <td>1.524929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9368</th>\n",
       "      <td>0.711893</td>\n",
       "      <td>-0.885711</td>\n",
       "      <td>-1.382583</td>\n",
       "      <td>-0.371269</td>\n",
       "      <td>-0.356723</td>\n",
       "      <td>0.529166</td>\n",
       "      <td>-0.455976</td>\n",
       "      <td>-0.862983</td>\n",
       "      <td>1.524929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9369</th>\n",
       "      <td>-0.314906</td>\n",
       "      <td>1.220031</td>\n",
       "      <td>1.958768</td>\n",
       "      <td>-0.336009</td>\n",
       "      <td>-0.629980</td>\n",
       "      <td>0.529166</td>\n",
       "      <td>-0.455976</td>\n",
       "      <td>1.158771</td>\n",
       "      <td>-0.655768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9370</th>\n",
       "      <td>-1.155903</td>\n",
       "      <td>-0.738501</td>\n",
       "      <td>-0.700391</td>\n",
       "      <td>-0.371269</td>\n",
       "      <td>-0.629980</td>\n",
       "      <td>0.529166</td>\n",
       "      <td>-0.455976</td>\n",
       "      <td>-0.862983</td>\n",
       "      <td>-0.655768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9371 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      population  daily_high_temperature  daily_low_temperature  \\\n",
       "0       0.019537                1.757667               2.411243   \n",
       "1       0.440036               -0.111259              -0.442828   \n",
       "2      -0.457680               -0.751302              -0.498517   \n",
       "3      -0.532001               -1.064923              -0.630779   \n",
       "4       1.627211                0.554386              -0.032120   \n",
       "...          ...                     ...                    ...   \n",
       "9366    0.911385               -1.071323              -0.916186   \n",
       "9367    0.739274                0.016750              -0.428906   \n",
       "9368    0.711893               -0.885711              -1.382583   \n",
       "9369   -0.314906                1.220031               1.958768   \n",
       "9370   -1.155903               -0.738501              -0.700391   \n",
       "\n",
       "      daily_precipitation  lockdown_percentage  gender_Male  \\\n",
       "0                0.545476             3.359580    -1.889767   \n",
       "1               -0.371269             0.463050     0.529166   \n",
       "2               -0.252009            -0.247420    -1.889767   \n",
       "3               -0.362972            -0.629980     0.529166   \n",
       "4               -0.361935             0.408398     0.529166   \n",
       "...                   ...                  ...          ...   \n",
       "9366             0.199104             1.173520     0.529166   \n",
       "9367            -0.371269            -0.356723     0.529166   \n",
       "9368            -0.371269            -0.356723     0.529166   \n",
       "9369            -0.336009            -0.629980     0.529166   \n",
       "9370            -0.371269            -0.629980     0.529166   \n",
       "\n",
       "      gender_Male and Female  political_affiliation_purple  \\\n",
       "0                   2.193096                     -0.862983   \n",
       "1                  -0.455976                     -0.862983   \n",
       "2                   2.193096                     -0.862983   \n",
       "3                  -0.455976                      1.158771   \n",
       "4                  -0.455976                      1.158771   \n",
       "...                      ...                           ...   \n",
       "9366               -0.455976                     -0.862983   \n",
       "9367               -0.455976                     -0.862983   \n",
       "9368               -0.455976                     -0.862983   \n",
       "9369               -0.455976                      1.158771   \n",
       "9370               -0.455976                     -0.862983   \n",
       "\n",
       "      political_affiliation_red  \n",
       "0                      1.524929  \n",
       "1                      1.524929  \n",
       "2                     -0.655768  \n",
       "3                     -0.655768  \n",
       "4                     -0.655768  \n",
       "...                         ...  \n",
       "9366                   1.524929  \n",
       "9367                   1.524929  \n",
       "9368                   1.524929  \n",
       "9369                  -0.655768  \n",
       "9370                  -0.655768  \n",
       "\n",
       "[9371 rows x 9 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file\n",
    "with open('best_random_forest_model.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    8379\n",
       "1     992\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_train_sc)\n",
    "pd.DataFrame(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "visiting_status_Suspended\n",
       "0    8315\n",
       "1    1056\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.001\n",
       "1      0.001\n",
       "2      0.000\n",
       "3      0.000\n",
       "4      0.000\n",
       "       ...  \n",
       "971    0.142\n",
       "972    0.138\n",
       "973    0.138\n",
       "974    0.139\n",
       "975    0.140\n",
       "Name: 1, Length: 976, dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('/Users/ianduke/Desktop/prison/data_update/TEST_APRIL.csv')\n",
    "test['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9340588988476313\n",
      "Precision: 0.75\n",
      "Recall: 0.5462962962962963\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_return_probabilities(new_data):\n",
    "    with open('best_random_forest_model.pkl', 'rb') as file:\n",
    "        loaded_model = pickle.load(file)\n",
    "    # Get the probability estimates for all classes\n",
    "    # probabilities = loaded_model.predict_proba(new_data)\n",
    "    # positive_class_probabilities = probabilities[:, 1]\n",
    "    # return positive_class_probabilities\n",
    "    prediction = loaded_model.predict(new_data)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    8379\n",
       "1     992\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(load_model_and_return_probabilities(x_train_sc)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate 'future' spreadsheet with predicted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries Modeling Preprocessing\n",
    "def prophet_preprocess_fac(df):\n",
    "    df['datetime_of_data'] = df['datetime_of_data'].apply(lambda x: parser.parse(x))\n",
    "    df['ds'] = pd.to_datetime(df['datetime_of_data'], format='%Y-%m-%d %H:%M:%S %Z')\n",
    "    df['ds'] = df['ds'].dt.tz_localize(None)\n",
    "    df['y'] = df[\"population\"]\n",
    "    df.set_index('ds', inplace=True)\n",
    "\n",
    "    daily_data = df.copy()\n",
    "    daily_data = daily_data['y']\n",
    "    #fill missing days with median rolling window = 5\n",
    "    rolling_median = daily_data.rolling(window=5, min_periods=1, center=True).median()\n",
    "    daily_data_filled = daily_data.fillna(rolling_median)\n",
    "    # Remove timezone from the 'Datetime' index\n",
    "    daily_data_filled.index = daily_data_filled.index.tz_localize(None)\n",
    "    \n",
    "    # Reset the index to make the Datetime a regular column\n",
    "    df_reset = daily_data_filled.reset_index()\n",
    "    #Isolate time and predictor columns\n",
    "    df_reset = df_reset[['ds', 'y']]\n",
    "\n",
    "    return df_reset\n",
    "\n",
    "# Grabbing future data\n",
    "def get_future_weather(future_date, location):\n",
    "    # Get today's date as a date object (not datetime)\n",
    "    today = datetime.now().date()\n",
    "\n",
    "    future_datetime = datetime.strptime(future_date, '%Y-%m-%d %H:%M:%S')\n",
    "    future_date = future_datetime.date()  # Get just the date part\n",
    "\n",
    "    # Calculate the difference in days (for checking)\n",
    "    delta = (future_date - today).days\n",
    "    if 0 <= delta <= 10:  # Adjust the range according to your subscription details\n",
    "        full_url = f\"http://api.weatherapi.com/v1/forecast.json?key={api_key}&q={location}&days=10\"\n",
    "\n",
    "        response = requests.get(full_url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            # Loop through all forecast days and find the target date\n",
    "            found = False\n",
    "            for forecast in data['forecast']['forecastday']:\n",
    "                if forecast['date'] == future_date.strftime('%Y-%m-%d'):\n",
    "                    avgtemp_f = forecast['day']['avgtemp_f']\n",
    "                    totalprecip_mm = forecast['day']['totalprecip_mm']\n",
    "    return avgtemp_f, totalprecip_mm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FPC ALDERSON\n",
      "Processing forecast for FCI ALICEVILLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FCI ALLENWOOD LOW\n",
      "Processing forecast for FCI ALLENWOOD MEDIUM\n",
      "Processing forecast for USP ALLENWOOD\n",
      "Processing forecast for FCI ASHLAND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for USP ATLANTA\n",
      "Processing forecast for USP ATWATER\n",
      "Processing forecast for FCI BASTROP\n",
      "Processing forecast for FCI BEAUMONT LOW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FCI BEAUMONT MEDIUM\n",
      "Processing forecast for USP BEAUMONT\n",
      "Processing forecast for FCI BECKLEY\n",
      "Processing forecast for FCI BENNETTSVILLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FCI BERLIN\n",
      "Processing forecast for USP BIG SANDY\n",
      "Processing forecast for FCI BIG SPRING\n",
      "Processing forecast for MDC BROOKLYN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FPC BRYAN\n",
      "Processing forecast for FCI BUTNER MEDIUM II\n",
      "Processing forecast for FCI BUTNER LOW\n",
      "Processing forecast for FCI BUTNER MEDIUM I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:53 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FMC BUTNER\n",
      "Processing forecast for USP CANAAN\n",
      "Processing forecast for FMC CARSWELL\n",
      "Processing forecast for MCC CHICAGO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FCI COLEMAN LOW\n",
      "Processing forecast for FCI COLEMAN MEDIUM\n",
      "Processing forecast for USP COLEMAN II\n",
      "Processing forecast for USP COLEMAN I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FCI CUMBERLAND\n",
      "Processing forecast for FCI DANBURY\n",
      "Processing forecast for FMC DEVENS\n",
      "Processing forecast for FCI DUBLIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FPC DULUTH\n",
      "Processing forecast for FCI EDGEFIELD\n",
      "Processing forecast for FCI EL RENO\n",
      "Processing forecast for FCI ELKTON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:54 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FCI ENGLEWOOD\n",
      "Processing forecast for FCI ESTILL\n",
      "Processing forecast for FCI FAIRTON\n",
      "Processing forecast for FCI FLORENCE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for USP FLORENCE ADMAX\n",
      "Processing forecast for USP FLORENCE - HIGH\n",
      "Processing forecast for FCI FORREST CITY MEDIUM\n",
      "Processing forecast for FCI FORREST CITY LOW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FCI FORT DIX\n",
      "Processing forecast for FMC FORT WORTH\n",
      "Processing forecast for FCI GILMER\n",
      "Processing forecast for FCI GREENVILLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for MDC GUAYNABO\n",
      "Processing forecast for FCI HAZELTON\n",
      "Processing forecast for USP HAZELTON\n",
      "Processing forecast for FCI HERLONG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FDC HONOLULU\n",
      "Processing forecast for FDC HOUSTON\n",
      "Processing forecast for FCI JESUP\n",
      "Processing forecast for FCI LA TUNA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for USP LEAVENWORTH\n",
      "Processing forecast for USP LEE\n",
      "Processing forecast for USP LEWISBURG\n",
      "Processing forecast for FMC LEXINGTON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FCI LOMPOC\n",
      "Processing forecast for USP LOMPOC\n",
      "Processing forecast for FCI LORETTO\n",
      "Processing forecast for MDC LOS ANGELES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FCI MANCHESTER\n",
      "Processing forecast for FCI MARIANNA\n",
      "Processing forecast for USP MARION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for USP MCCREARY\n",
      "Processing forecast for FCI MCDOWELL\n",
      "Processing forecast for FCI MCKEAN\n",
      "Processing forecast for FCI MEMPHIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FCI MENDOTA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FCI MIAMI\n",
      "Processing forecast for FDC MIAMI\n",
      "Processing forecast for FCI MILAN\n",
      "Processing forecast for FPC MONTGOMERY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FCI MORGANTOWN\n",
      "Processing forecast for MCC NEW YORK\n",
      "Processing forecast for FCI OAKDALE II\n",
      "Processing forecast for FCI OAKDALE I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FTC OKLAHOMA CITY\n",
      "Processing forecast for FCI OTISVILLE\n",
      "Processing forecast for FCI OXFORD\n",
      "Processing forecast for FCI PEKIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FPC PENSACOLA\n",
      "Processing forecast for FCI PETERSBURG MEDIUM\n",
      "Processing forecast for FCI PETERSBURG LOW\n",
      "Processing forecast for FDC PHILADELPHIA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FCI PHOENIX\n",
      "Processing forecast for FCI POLLOCK\n",
      "Processing forecast for USP POLLOCK\n",
      "Processing forecast for FCI RAY BROOK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FMC ROCHESTER\n",
      "Processing forecast for FCI SAFFORD\n",
      "Processing forecast for MCC SAN DIEGO\n",
      "Processing forecast for FCI SANDSTONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FCI SCHUYLKILL\n",
      "Processing forecast for FCI SEAGOVILLE\n",
      "Processing forecast for FDC SEATAC\n",
      "Processing forecast for FCI SHERIDAN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for MCFP SPRINGFIELD\n",
      "Processing forecast for FCI TALLADEGA\n",
      "Processing forecast for FCI TALLAHASSEE\n",
      "Processing forecast for FCI TERMINAL ISLAND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FCI TERRE HAUTE\n",
      "Processing forecast for USP TERRE HAUTE\n",
      "Processing forecast for FCI TEXARKANA\n",
      "Processing forecast for FCI THOMSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FCI THREE RIVERS\n",
      "Processing forecast for FCI TUCSON\n",
      "Processing forecast for USP TUCSON\n",
      "Processing forecast for FCI VICTORVILLE MEDIUM I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:49:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:49:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:49:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:49:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:49:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:49:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:49:00 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FCI VICTORVILLE MEDIUM II\n",
      "Processing forecast for USP VICTORVILLE\n",
      "Processing forecast for FCI WASECA\n",
      "Processing forecast for FCI WILLIAMSBURG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:49:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:49:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:49:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:49:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:49:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:49:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:49:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for FPC YANKTON\n",
      "Processing forecast for FCI YAZOO CITY MEDIUM\n",
      "Processing forecast for FCI YAZOO CITY LOW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:49:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:49:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:49:00 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for USP YAZOO CITY\n",
      "Processing forecast for USP THOMSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:49:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forecast for MCC New York\n",
      "Not enough data to fit the model for MCC New York.\n"
     ]
    }
   ],
   "source": [
    "facility_names = data['title'].unique()\n",
    "api_key = 'cae38d1f50ab4d78b6041519241204'\n",
    "\n",
    "facility_names = data['title'].unique()\n",
    "\n",
    "# Create a master DataFrame to hold all future forecasts for all facilities\n",
    "master_df = pd.DataFrame()\n",
    "\n",
    "for facility in facility_names:\n",
    "    print(f\"Processing forecast for {facility}\")\n",
    "    data_df = data[data['title'] == facility].copy()\n",
    "    \n",
    "    # Perform preprocessing for Prophet\n",
    "    train = prophet_preprocess_fac(data_df)\n",
    "    \n",
    "    # Check if there are at least two rows to fit the model\n",
    "    if len(train) < 2:\n",
    "        print(f\"Not enough data to fit the model for {facility}.\")\n",
    "        continue\n",
    "\n",
    "    m = Prophet()\n",
    "    m.fit(train)\n",
    "    \n",
    "    future = m.make_future_dataframe(periods=9)\n",
    "    forecast = m.predict(future)\n",
    "    new_columns = forecast[['ds', 'yhat']]\n",
    "    \n",
    "    # Get the current date and time\n",
    "    current_datetime = datetime.now()\n",
    "    \n",
    "    # Filter the DataFrame for future dates only\n",
    "    future_dates_data = new_columns[new_columns['ds'] > current_datetime]\n",
    "    \n",
    "    # Ensure we don't take the first row as it is the last known data point, not a future prediction\n",
    "    future_dates_data = future_dates_data[future_dates_data['ds'] > future_dates_data['ds'].min()]\n",
    "    \n",
    "    # Add facility name to future data df\n",
    "    future_dates_data['title'] = facility\n",
    "    \n",
    "    # Get the zip code from the original data\n",
    "    zip_code = data_df['zip_code'].dropna().iloc[0] if not data_df['zip_code'].isnull().all() else 'Unknown'\n",
    "    future_dates_data['zip'] = zip_code\n",
    "    \n",
    "    # Initialize columns for weather data\n",
    "    future_dates_data['avgtemp_f'] = None\n",
    "    future_dates_data['totalprecip_mm'] = None\n",
    "    \n",
    "    for i, row in future_dates_data.iterrows():\n",
    "        try:\n",
    "            # Call your function to get the weather data\n",
    "            avgtemp_f, totalprecip_mm = get_future_weather(str(row['ds']), row['zip'])\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while fetching weather for {facility} on {row['ds']}: {e}\")\n",
    "            avgtemp_f, totalprecip_mm = None, None  # Set default values in case of an error\n",
    "\n",
    "        # Set the retrieved or default values in the DataFrame\n",
    "        future_dates_data.at[i, 'avgtemp_f'] = avgtemp_f\n",
    "        future_dates_data.at[i, 'totalprecip_mm'] = totalprecip_mm\n",
    "\n",
    "    # Append this facility's forecast to the master DataFrame\n",
    "    master_df = pd.concat([master_df, future_dates_data], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>yhat</th>\n",
       "      <th>title</th>\n",
       "      <th>zip</th>\n",
       "      <th>avgtemp_f</th>\n",
       "      <th>totalprecip_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ds, yhat, title, zip, avgtemp_f, totalprecip_mm]\n",
       "Index: []"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.sort_values(by = 'ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now let's use our model to make predictions on the future dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate closure predictions on future spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_return_probabilities(new_data: pd.DataFrame) -> np.array:\n",
    "    # Load the model\n",
    "    with open('best_RF_model.pkl', 'rb') as file:\n",
    "        loaded_model = pickle.load(file)\n",
    "\n",
    "    # Ensure new_data is scaled similarly to training data before getting logits\n",
    "    decision_scores = loaded_model.decision_function(new_data)\n",
    "    \n",
    "    # Convert decision scores to probabilities\n",
    "    probabilities = expit(decision_scores)  # Using the sigmoid function\n",
    "    \n",
    "    return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>yhat</th>\n",
       "      <th>title</th>\n",
       "      <th>zip</th>\n",
       "      <th>avgtemp_f</th>\n",
       "      <th>totalprecip_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ds, yhat, title, zip, avgtemp_f, totalprecip_mm]\n",
       "Index: []"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daily_temperature</th>\n",
       "      <th>daily_precipitation</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.045556e-01</td>\n",
       "      <td>-0.011103</td>\n",
       "      <td>-0.456432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.129381e-01</td>\n",
       "      <td>-0.352966</td>\n",
       "      <td>-0.903170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.637556e-01</td>\n",
       "      <td>-0.372830</td>\n",
       "      <td>-1.347932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.521174e-07</td>\n",
       "      <td>-0.372830</td>\n",
       "      <td>-1.150260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.301287e+00</td>\n",
       "      <td>-0.366557</td>\n",
       "      <td>-1.713625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9198</th>\n",
       "      <td>-1.661224e-01</td>\n",
       "      <td>-0.372830</td>\n",
       "      <td>0.405417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9199</th>\n",
       "      <td>-2.907137e-01</td>\n",
       "      <td>-0.372830</td>\n",
       "      <td>0.308558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9200</th>\n",
       "      <td>-1.024418e+00</td>\n",
       "      <td>-0.372830</td>\n",
       "      <td>0.207745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9201</th>\n",
       "      <td>4.360686e-01</td>\n",
       "      <td>-0.372830</td>\n",
       "      <td>1.097268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9202</th>\n",
       "      <td>3.530078e-01</td>\n",
       "      <td>-0.372830</td>\n",
       "      <td>0.425184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9203 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      daily_temperature  daily_precipitation  population\n",
       "0          3.045556e-01            -0.011103   -0.456432\n",
       "1          7.129381e-01            -0.352966   -0.903170\n",
       "2          4.637556e-01            -0.372830   -1.347932\n",
       "3         -7.521174e-07            -0.372830   -1.150260\n",
       "4         -1.301287e+00            -0.366557   -1.713625\n",
       "...                 ...                  ...         ...\n",
       "9198      -1.661224e-01            -0.372830    0.405417\n",
       "9199      -2.907137e-01            -0.372830    0.308558\n",
       "9200      -1.024418e+00            -0.372830    0.207745\n",
       "9201       4.360686e-01            -0.372830    1.097268\n",
       "9202       3.530078e-01            -0.372830    0.425184\n",
       "\n",
       "[9203 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_time_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.set_index('ds', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_pred = master_df[['avgtemp_f', 'totalprecip_mm', 'yhat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_pred.rename(columns={'avgtemp_f': 'daily_temperature', 'totalprecip_mm': 'daily_precipitation', 'yhat':'population'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daily_temperature</th>\n",
       "      <th>daily_precipitation</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [daily_temperature, daily_precipitation, population]\n",
       "Index: []"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yintianyunxi/Desktop/BOP_Project_Entrepreneurship/lockdown_prediction_modeling.ipynb Cell 77\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yintianyunxi/Desktop/BOP_Project_Entrepreneurship/lockdown_prediction_modeling.ipynb#Y211sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yintianyunxi/Desktop/BOP_Project_Entrepreneurship/lockdown_prediction_modeling.ipynb#Y211sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Fit the scaler to the data and transform it\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yintianyunxi/Desktop/BOP_Project_Entrepreneurship/lockdown_prediction_modeling.ipynb#Y211sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m x_pred_sc_array \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mfit_transform(master_df_pred)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yintianyunxi/Desktop/BOP_Project_Entrepreneurship/lockdown_prediction_modeling.ipynb#Y211sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Convert the scaled array back to a DataFrame\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yintianyunxi/Desktop/BOP_Project_Entrepreneurship/lockdown_prediction_modeling.ipynb#Y211sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m x_pred_sc \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(x_pred_sc_array, columns\u001b[39m=\u001b[39mmaster_df_pred\u001b[39m.\u001b[39mcolumns)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:824\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 824\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:861\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m    860\u001b[0m first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 861\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m    862\u001b[0m     X,\n\u001b[1;32m    863\u001b[0m     accept_sparse\u001b[39m=\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    864\u001b[0m     dtype\u001b[39m=\u001b[39mFLOAT_DTYPES,\n\u001b[1;32m    865\u001b[0m     force_all_finite\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    866\u001b[0m     reset\u001b[39m=\u001b[39mfirst_call,\n\u001b[1;32m    867\u001b[0m )\n\u001b[1;32m    868\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m    870\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[1;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[1;32m    930\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 931\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    932\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    933\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    934\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    935\u001b[0m         )\n\u001b[1;32m    937\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    938\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "# first let's rescale our data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the data and transform it\n",
    "x_pred_sc_array = scaler.fit_transform(master_df_pred)\n",
    "\n",
    "# Convert the scaled array back to a DataFrame\n",
    "x_pred_sc = pd.DataFrame(x_pred_sc_array, columns=master_df_pred.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = load_model_and_return_probabilities(x_pred_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['lockdown_probability'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>title</th>\n",
       "      <th>zip</th>\n",
       "      <th>daily_temperature</th>\n",
       "      <th>daily_precipitation</th>\n",
       "      <th>lockdown_probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-04-20 20:17:59</th>\n",
       "      <td>692.375769</td>\n",
       "      <td>FPC ALDERSON</td>\n",
       "      <td>24910</td>\n",
       "      <td>50.6</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.484448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-21 20:17:59</th>\n",
       "      <td>693.479690</td>\n",
       "      <td>FPC ALDERSON</td>\n",
       "      <td>24910</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-22 20:17:59</th>\n",
       "      <td>693.544551</td>\n",
       "      <td>FPC ALDERSON</td>\n",
       "      <td>24910</td>\n",
       "      <td>44.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-23 20:17:59</th>\n",
       "      <td>694.328015</td>\n",
       "      <td>FPC ALDERSON</td>\n",
       "      <td>24910</td>\n",
       "      <td>51.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-24 20:17:59</th>\n",
       "      <td>692.674228</td>\n",
       "      <td>FPC ALDERSON</td>\n",
       "      <td>24910</td>\n",
       "      <td>47.3</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.482658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-22 20:49:57</th>\n",
       "      <td>1489.104776</td>\n",
       "      <td>USP YAZOO CITY</td>\n",
       "      <td>39194</td>\n",
       "      <td>55.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-23 20:49:57</th>\n",
       "      <td>1490.937264</td>\n",
       "      <td>USP YAZOO CITY</td>\n",
       "      <td>39194</td>\n",
       "      <td>60.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-24 20:49:57</th>\n",
       "      <td>1489.483562</td>\n",
       "      <td>USP YAZOO CITY</td>\n",
       "      <td>39194</td>\n",
       "      <td>65.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.508537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-25 20:49:57</th>\n",
       "      <td>1489.814572</td>\n",
       "      <td>USP YAZOO CITY</td>\n",
       "      <td>39194</td>\n",
       "      <td>65.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.509327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-26 20:49:57</th>\n",
       "      <td>1490.856596</td>\n",
       "      <td>USP YAZOO CITY</td>\n",
       "      <td>39194</td>\n",
       "      <td>71.6</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.516245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>854 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      population           title    zip daily_temperature  \\\n",
       "ds                                                                          \n",
       "2024-04-20 20:17:59   692.375769    FPC ALDERSON  24910              50.6   \n",
       "2024-04-21 20:17:59   693.479690    FPC ALDERSON  24910              42.0   \n",
       "2024-04-22 20:17:59   693.544551    FPC ALDERSON  24910              44.6   \n",
       "2024-04-23 20:17:59   694.328015    FPC ALDERSON  24910              51.1   \n",
       "2024-04-24 20:17:59   692.674228    FPC ALDERSON  24910              47.3   \n",
       "...                          ...             ...    ...               ...   \n",
       "2024-04-22 20:49:57  1489.104776  USP YAZOO CITY  39194              55.2   \n",
       "2024-04-23 20:49:57  1490.937264  USP YAZOO CITY  39194              60.7   \n",
       "2024-04-24 20:49:57  1489.483562  USP YAZOO CITY  39194              65.1   \n",
       "2024-04-25 20:49:57  1489.814572  USP YAZOO CITY  39194              65.9   \n",
       "2024-04-26 20:49:57  1490.856596  USP YAZOO CITY  39194              71.6   \n",
       "\n",
       "                    daily_precipitation  lockdown_probability  \n",
       "ds                                                             \n",
       "2024-04-20 20:17:59                0.12              0.484448  \n",
       "2024-04-21 20:17:59                 0.0              0.475626  \n",
       "2024-04-22 20:17:59                 0.0              0.478175  \n",
       "2024-04-23 20:17:59                 0.0              0.484561  \n",
       "2024-04-24 20:17:59                0.55              0.482658  \n",
       "...                                 ...                   ...  \n",
       "2024-04-22 20:49:57                 0.0              0.498641  \n",
       "2024-04-23 20:49:57                 0.0              0.504066  \n",
       "2024-04-24 20:49:57                0.05              0.508537  \n",
       "2024-04-25 20:49:57                0.05              0.509327  \n",
       "2024-04-26 20:49:57                0.44              0.516245  \n",
       "\n",
       "[854 rows x 6 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
